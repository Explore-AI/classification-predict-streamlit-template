{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpIPMNPoU_-p"
   },
   "source": [
    "# Advance Classification Solution\n",
    "### EDSA - Climate Change Belief Analysis 2022 \n",
    "#### RecycleStats Solutions - Team 12 EDSA\n",
    "\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "Hence, We will be creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n",
    "\n",
    "## Outline\n",
    "We will covering the following areas in hope to archieving the set objective:\n",
    "- Importing Packages\n",
    "- Collect Data\n",
    "    - Load Data\n",
    "    - Review Data to gain insight to nature of Dataset\n",
    "- Clean Data\n",
    "    - Ensure Correct Formatting\n",
    "    - Text Cleaning (Removing Noise, Tokenisation, Stemming, Remove Stop Words, Lemmatisation)\n",
    "    - Text Feature Extraction \n",
    "        - n-grams\n",
    "        - Bag of words\n",
    "    - Name file appropriately\n",
    "- Exploratory Data Analysis (EDA)\n",
    "    - Missing Data Check\n",
    "    - Data Range Check\n",
    "    - Check for Outlier\n",
    "    - Collinarity & Multicollinarity\n",
    "- Data Engineering\n",
    "    - Standardization\n",
    "    - Feature Selection\n",
    "    - Train/Test Split\n",
    "- Modeling\n",
    "- Model Performance\n",
    "    - Model Testing\n",
    "    - Model Selection\n",
    "- Model Explanations\n",
    "- Model Deployment\n",
    "    - To GitHub/Kaggle/Commet/AWS EC2\n",
    "- Conclusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "...........................\n",
    "\n",
    "So let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "## Table of Content\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Collect Data</a>\n",
    "\n",
    "<a href=#three>3. Clean Data</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)<a>\n",
    "\n",
    "<a href=#five>5. Data Engineering</a>\n",
    "\n",
    "<a href=#six>6. Modeling</a>\n",
    "\n",
    "<a href=#seven>7. Model Performance</a>\n",
    "\n",
    "<a href=#eight>8. Model Explanations</a>\n",
    "\n",
    "<a href=#nine>9. Model Deployment</a>\n",
    "\n",
    "<a href=#ten>10. Conclusion</a>\n",
    "\n",
    "<a href=#eleven>11. Recommendation</a>\n",
    "\n",
    "<a href=#ref>Reference Document Links</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKmhMwlDU_-u"
   },
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "In this section you are required to import........... briefly discuss, the libraries that will be used throughout your analysis and modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C68jzOFpU_-2"
   },
   "source": [
    "#### 1.1 Ensure you've got NLTK Corpora installed\n",
    "Some of the `nltk` text processing involve a lookup operation. For example, to find all [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) in a given string of text, we require a list of all possible stopwords in the English language to use for the lookup. Such a list is refered to as a [corpus](https://en.wikipedia.org/wiki/Text_corpus). Therefore, first download the corpora we're going use if you don't have it installed, otherwise we may get a lookup error! Watch out specifically for the `tokenize` and `stopwords` sections. Not to worry, as we can easily avoid these errors by downloading the [corpora](http://www.nltk.org/nltk_data/) using the `nltk` downloader tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29356,
     "status": "error",
     "timestamp": 1560340175121,
     "user": {
      "displayName": "Bryan Davies",
      "photoUrl": "",
      "userId": "03059035420523728518"
     },
     "user_tz": -120
    },
    "id": "w8Iw1yCRU_-2",
    "outputId": "188501d1-fcf6-45be-8a45-56f885491dcd"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "if you don't have installed, the NLTK corpora, Remove Hashtag below and Run \n",
    "'''\n",
    "import nltk\n",
    "\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lct3bK9aU_-7"
   },
   "source": [
    "You should see this pop-up box. \n",
    "\n",
    "**NOTE:** the box might pop-up in the backround, in which case you should use `alt + tab` to switch to the downloader window.\n",
    "\n",
    "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/nltk_downloader.png?raw=true\" width=50%/> \n",
    "\n",
    "Use it to navigate to the item we need to download: \n",
    "- stopwords corpus (Corpora tab)\n",
    "- punkt tokenizer models (Models tab)\n",
    "\n",
    "Navigate to these, click the download button, and exit the downloader when finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQm0O5XHU_-z",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# All Importing should be done here\n",
    "\n",
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd                                                   # for loading CSV data\n",
    "import numpy as np                                                    # Used for mathematical operations\n",
    "import matplotlib.pyplot as plt                                       # for Graphical Representation\n",
    "%matplotlib inline                                                    # \n",
    "import seaborn as sns                                                 # for specialized plots\n",
    "import re                                               \n",
    "sns.set()                                                             # set plot style\n",
    "\n",
    "# Libraries for data preparation\n",
    "from nltk.corpus import stopwords                                     # \n",
    "import string                                                         #\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer        #\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer     #\n",
    "from nltk.stem import WordNetLemmatizer                               #\n",
    "from nltk.util import ngrams                                          #\n",
    "from statsmodels.graphics.correlation import plot_corr                # To plot correlation heatmap\n",
    "from sklearn.preprocessing import StandardScaler                      # For standardizing features\n",
    "\n",
    "# Libraries for Model Building\n",
    "from sklearn.model_selection import train_test_split                  # To split the data into training and testing data\n",
    "\n",
    "# Libraries for calculating performance metrics\n",
    "\n",
    "\n",
    "# Libraries to Save/Restore Models\n",
    "import pickle\n",
    "\n",
    "# Setting global constants to ensure notebook results are reproducible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Collect Data\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "#df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Dataset\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A brief on dataset\n",
    "\n",
    "............"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 3. Clean Data\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Let's get the data and clean it up a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKeKPQWkU_-9"
   },
   "source": [
    "#### 3.1 Format Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3G_aB4hU__G",
    "outputId": "92110f2c-5cab-4f7b-a5b3-4a9b0be103e3"
   },
   "source": [
    "#### 3.2 Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "GnKe3gyoU__Z"
   },
   "outputs": [],
   "source": [
    "# Removing Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CUATZmo5U__h",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9nnIjyhU__t",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BRY-EGeuU__7",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XY1p3uZVAAS"
   },
   "outputs": [],
   "source": [
    "# Remove StopWords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Text Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Rearrange File Appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqeL2KJ4VABR"
   },
   "source": [
    "### If you will be applying CountVectorizer then we might boycourt the huddles of tokenization down to Rearranging files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Missing Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Range Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Check for Outlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Collinarity & Multicollinarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Data Engineering\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Modeling\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Performance\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Model Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Model Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "## 8. Model Explanations\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nine\"></a>\n",
    "## 9. Model Deployment\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  To GitHub / To Commet / AWS EC2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ten\"></a>\n",
    "## 10. Conclusion\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "..........................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eleven\"></a>\n",
    "## 11. Recommendation\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref\"></a>\n",
    "## Reference Links\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [GitHub Collab Ref.](https://github.com/)\n",
    "* [Commet Collab Ref](https://www.comet.ml/) \n",
    "* [Kaggle Collab Ref](https://www.kaggle.com/c/edsa-climate-change-belief-analysis-2022/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VCXae5QXU__Z",
    "wzM8TbWBU__h",
    "FvA-QZmRU__r",
    "hAUkklVXU__6",
    "rFln-NFtVAAI",
    "UZomXVzoVAAR",
    "qp-n688CVAAc",
    "tGmGzrbsVAAf",
    "oFzCFS89VABM",
    "TlO1q-zlVABg"
   ],
   "name": "3_How-do-machines-understand language.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
