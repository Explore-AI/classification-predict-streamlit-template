{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13038491",
   "metadata": {},
   "source": [
    "# CLIMATE CHANGE TWEET CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18507453",
   "metadata": {},
   "source": [
    "# Lumina Datamatics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd77c07",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f9ef0",
   "metadata": {},
   "source": [
    "### Team Members\n",
    "Abidence\n",
    "\n",
    "Ayanda\n",
    "\n",
    "Emmanuel \n",
    "\n",
    "Mathapelo\n",
    "\n",
    "Mpho\n",
    "\n",
    "Nyiko\n",
    "\n",
    "Tshepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b3c74",
   "metadata": {},
   "source": [
    "Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75349cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f7ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style\n",
    "import matplotlib.style as style \n",
    "sns.set(font_scale=1.5)\n",
    "style.use('seaborn-pastel')\n",
    "style.use('seaborn-poster')\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads\n",
    "#nlp = spacy.load('en')\n",
    "nlp = spacy.blank('en')\n",
    "nlp = spacy.blank('zh')\n",
    "nlp = spacy.blank('xx') # multilanguage (spaCy provides support for languages) \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5284405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import en_core_web_sm\n",
    "from collections import Counter\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords, wordnet  \n",
    "from sklearn.feature_extraction.text import CountVectorizer   \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eaca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building classification models\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e75340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0e1374f",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229877bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\climate.intern\\OneDrive - MSF\\Documents\\GitHub\\classification-predict-streamlit-template\\train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\climate.intern\\OneDrive - MSF\\Documents\\GitHub\\classification-predict-streamlit-template\\test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d818fb",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf194e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install powerbiclient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc7f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from powerbiclient import Report, models\n",
    "from io import StringIO\n",
    "from ipywidgets import interact\n",
    "import requests\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c064fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for duplicates\n",
    "percent_duplicates = round((1-(train_df['message'].nunique()/len(train_df['message'])))*100,2)\n",
    "print('Duplicated tweets in train data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfff723",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eeffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(df):\n",
    "\n",
    "    df = train_df.copy()\n",
    "    sentiment = df['sentiment']\n",
    "    word_sentiment = []\n",
    "\n",
    "    for i in sentiment :\n",
    "        if i == 1 :\n",
    "            word_sentiment.append('Pro')\n",
    "        elif i == 0 :\n",
    "            word_sentiment.append('Neutral')\n",
    "        elif i == -1 :\n",
    "            word_sentiment.append('Anti')\n",
    "        else :\n",
    "            word_sentiment.append('News')\n",
    "\n",
    "    df['sentiment'] = word_sentiment\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = update(train_df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a2002",
   "metadata": {},
   "source": [
    "### Streamlit app for the Climate Change Tweet Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "# Set up the app title and description\n",
    "st.title('Climate Change Tweet Classification')\n",
    "st.write('Lumina Datamatics')\n",
    "st.write('Team Members: Abidence, Ayanda, Emmanuel, Mathapelo, Mpho, Nyiko, Tshepo')\n",
    "\n",
    "# Install the required Spacy model\n",
    "spacy_model = 'en_core_web_sm'\n",
    "spacy.cli.download(spacy_model)\n",
    "nlp = spacy.load(spacy_model)\n",
    "\n",
    "# Function to classify the tweet\n",
    "def classify_tweet(tweet):\n",
    "    # Your classification logic goes here\n",
    "    # Example: using a dummy classifier that classifies all tweets as positive\n",
    "    return 'Positive'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216020ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main function to run the app\n",
    "def main():\n",
    "    # Add a sidebar title\n",
    "    st.sidebar.title('Climate Change Tweet Classification')\n",
    "\n",
    "    # Add a file uploader to upload the CSV file\n",
    "    uploaded_file = st.sidebar.file_uploader('Upload a CSV file', type='csv')\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(uploaded_file)\n",
    "\n",
    "        # Display the data frame\n",
    "        st.subheader('Data')\n",
    "        st.write(df)\n",
    "\n",
    "        # Perform tweet classification\n",
    "        st.subheader('Classification Results')\n",
    "        for index, row in df.iterrows():\n",
    "            tweet = row['tweet']\n",
    "            classification = classify_tweet(tweet)\n",
    "            st.write(f'Tweet: {tweet}')\n",
    "            st.write(f'Classification: {classification}')\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
