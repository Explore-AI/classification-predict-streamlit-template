{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               #For data loading and data manipulation\n",
    "import seaborn as sns             #For data visualization \n",
    "import matplotlib.pyplot as plt   #For data visualization\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords #For stopword removals\n",
    "\n",
    "import string                     #For Punctuations\n",
    "\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, TreebankWordTokenizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display.max_colwidth option  set to None to show all text content without truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Your code to read the DataFrame\n",
    "df1 = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_with_no_labels.csv')\n",
    "df=pd.concat([df1,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It's not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Worth a read whether you do or don't believe in climate change https://t.co/ggLZVNYjun https://t.co/7AFE2mAH8j</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@AceofSpadesHQ My 8yo nephew is inconsolable. He wants to die of old age like me, but will perish in the fiery hellscape of climate change.</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RT @paigetweedy: no offense… but like… how do you just not believe… in global warming………</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0        1.0   \n",
       "1        1.0   \n",
       "2        2.0   \n",
       "3        1.0   \n",
       "4        1.0   \n",
       "5        1.0   \n",
       "6        1.0   \n",
       "7        1.0   \n",
       "8        1.0   \n",
       "9        1.0   \n",
       "\n",
       "                                                                                                                                                    message  \\\n",
       "0              PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable   \n",
       "1                                                                                            It's not like we lack evidence of anthropogenic global warming   \n",
       "2              RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…   \n",
       "3                                                       #TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD   \n",
       "4                                RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight   \n",
       "5                                            Worth a read whether you do or don't believe in climate change https://t.co/ggLZVNYjun https://t.co/7AFE2mAH8j   \n",
       "6                                   RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R   \n",
       "7  RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦   \n",
       "8               @AceofSpadesHQ My 8yo nephew is inconsolable. He wants to die of old age like me, but will perish in the fiery hellscape of climate change.   \n",
       "9                                                                  RT @paigetweedy: no offense… but like… how do you just not believe… in global warming………   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  \n",
       "5   425577  \n",
       "6   294933  \n",
       "7   992717  \n",
       "8   664510  \n",
       "9   260471  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data snippet shown above, we see that the message column contains some noise (stop words, puntuations, mentions, hashtags and even urls). We need to deal with the noise before proceeding to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26365, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26365 entries, 0 to 10545\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sentiment  15819 non-null  float64\n",
      " 1   message    26365 non-null  object \n",
      " 2   tweetid    26365 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 823.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info() #Let's see our datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHSCAYAAAANN9SZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSFElEQVR4nO3de1wUdf8+/muRg2CwCgLrKikqIghqYiGYSSIqiuQpVLzJFA99PSCKebgzhe6EtDsPhWdNPMadeco0VKwoVAQxShHN0hSSFVFYENdFYX5/+GM+rpixCiww1/Px2MctM6/dfU1zw177npn3yARBEEBEREQkYUaGboCIiIjI0BiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8owN3UB9UV5ejuvXr8PS0hIymczQ7RAREVEVCIKA4uJiKJVKGBn9/TgQA1EVXb9+HQ4ODoZug4iIiJ5BdnY2WrVq9bfrGYiqyNLSEsDD/6BWVlYG7oaIiIiqoqioCA4ODuLn+N9hIKqiisNkVlZWDERERET1zD+d7sKTqomIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPKMDd0AERFRXSGLkhm6BckSFgkGfX+OEBEREZHkMRARERGR5DEQERERkeQxEBEREZHkMRARERGR5DEQERERkeQxEBEREZHkMRARERGR5DEQERERkeQxEBEREZHkMRARERGR5DEQERERkeQxEBEREZHkMRARERGR5DEQERERkeQxEBEREZHkMRARERGR5Bk0ED148AALFiyAo6MjzM3N0bZtW3zwwQcoLy8XawRBQGRkJJRKJczNzeHj44PMzEyd19FqtZg+fTqaN2+OJk2aIDAwEDk5OTo1BQUFCAkJgVwuh1wuR0hICAoLC2tjM4mIiKiOM2ggWrJkCdauXYvY2FhkZWVh6dKl+Pjjj/HZZ5+JNUuXLsWyZcsQGxuLtLQ0KBQK+Pn5obi4WKwJDw/H3r17ER8fj+TkZNy5cwcBAQEoKysTa4KDg5GRkYGEhAQkJCQgIyMDISEhtbq9REREVDfJBEEQDPXmAQEBsLe3x6ZNm8Rlw4cPh4WFBbZt2wZBEKBUKhEeHo65c+cCeDgaZG9vjyVLlmDy5MlQq9WwtbXFtm3bMHLkSADA9evX4eDggEOHDqF///7IysqCq6srUlJS4OnpCQBISUmBl5cXLly4AGdn53/staioCHK5HGq1GlZWVjXwX4OIiAxNFiUzdAuSJSyqmThS1c9vg44Qvfrqqzh27Bh+++03AMAvv/yC5ORkDBw4EABw5coVqFQq9OvXT3yOmZkZevfujRMnTgAA0tPTcf/+fZ0apVIJNzc3sebkyZOQy+ViGAKAHj16QC6XizWP02q1KCoq0nkQERFRw2RsyDefO3cu1Go1OnbsiEaNGqGsrAyLFy/G6NGjAQAqlQoAYG9vr/M8e3t7XL16VawxNTVFs2bNKtVUPF+lUsHOzq7S+9vZ2Yk1j4uJiUFUVNTzbSARERHVCwYdIfrf//6H7du3Y+fOnThz5gy2bNmC//73v9iyZYtOnUymO4QpCEKlZY97vOZJ9U97nfnz50OtVouP7Ozsqm4WERER1TMGHSF69913MW/ePIwaNQoA4O7ujqtXryImJgZjx46FQqEA8HCEp0WLFuLz8vLyxFEjhUKB0tJSFBQU6IwS5eXlwdvbW6y5ceNGpfe/efNmpdGnCmZmZjAzM6ueDSUiIqI6zaAjRHfv3oWRkW4LjRo1Ei+7d3R0hEKhwNGjR8X1paWlSEpKEsOOh4cHTExMdGpyc3Nx7tw5scbLywtqtRqpqalizalTp6BWq8UaIiIiki6DjhANHjwYixcvxosvvohOnTrh559/xrJlyzB+/HgADw9zhYeHIzo6Gk5OTnByckJ0dDQsLCwQHBwMAJDL5QgNDUVERARsbGxgbW2N2bNnw93dHX379gUAuLi4YMCAAZg4cSLWrVsHAJg0aRICAgKqdIUZERERNWwGDUSfffYZ3n//fUyZMgV5eXlQKpWYPHkyFi5cKNbMmTMHGo0GU6ZMQUFBATw9PXHkyBFYWlqKNcuXL4exsTGCgoKg0Wjg6+uLuLg4NGrUSKzZsWMHwsLCxKvRAgMDERsbW3sbS0RERHWWQechqk84DxERUcPHeYgMR9LzEBERERHVBQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5Bg1Ebdq0gUwmq/SYOnUqAEAQBERGRkKpVMLc3Bw+Pj7IzMzUeQ2tVovp06ejefPmaNKkCQIDA5GTk6NTU1BQgJCQEMjlcsjlcoSEhKCwsLC2NpOIiIjqOIMGorS0NOTm5oqPo0ePAgDefPNNAMDSpUuxbNkyxMbGIi0tDQqFAn5+figuLhZfIzw8HHv37kV8fDySk5Nx584dBAQEoKysTKwJDg5GRkYGEhISkJCQgIyMDISEhNTuxhIREVGdJRMEQTB0ExXCw8PxzTff4NKlSwAApVKJ8PBwzJ07F8DD0SB7e3ssWbIEkydPhlqthq2tLbZt24aRI0cCAK5fvw4HBwccOnQI/fv3R1ZWFlxdXZGSkgJPT08AQEpKCry8vHDhwgU4OztXqbeioiLI5XKo1WpYWVnVwNYTEZGhyaJkhm5BsoRFNRNHqvr5XWfOISotLcX27dsxfvx4yGQyXLlyBSqVCv369RNrzMzM0Lt3b5w4cQIAkJ6ejvv37+vUKJVKuLm5iTUnT56EXC4XwxAA9OjRA3K5XKx5Eq1Wi6KiIp0HERERNUx1JhDt27cPhYWFePvttwEAKpUKAGBvb69TZ29vL65TqVQwNTVFs2bNnlpjZ2dX6f3s7OzEmieJiYkRzzmSy+VwcHB45m0jIiKiuq3OBKJNmzbB398fSqVSZ7lMpjt8KQhCpWWPe7zmSfX/9Drz58+HWq0WH9nZ2VXZDCIiIqqH6kQgunr1KhITEzFhwgRxmUKhAIBKozh5eXniqJFCoUBpaSkKCgqeWnPjxo1K73nz5s1Ko0+PMjMzg5WVlc6DiIiIGqY6EYg2b94MOzs7DBo0SFzm6OgIhUIhXnkGPDzPKCkpCd7e3gAADw8PmJiY6NTk5ubi3LlzYo2XlxfUajVSU1PFmlOnTkGtVos1REREJG3Ghm6gvLwcmzdvxtixY2Fs/H/tyGQyhIeHIzo6Gk5OTnByckJ0dDQsLCwQHBwMAJDL5QgNDUVERARsbGxgbW2N2bNnw93dHX379gUAuLi4YMCAAZg4cSLWrVsHAJg0aRICAgKqfIUZERERNWwGD0SJiYm4du0axo8fX2ndnDlzoNFoMGXKFBQUFMDT0xNHjhyBpaWlWLN8+XIYGxsjKCgIGo0Gvr6+iIuLQ6NGjcSaHTt2ICwsTLwaLTAwELGxsTW/cURERFQv1Kl5iOoyzkNERNTwcR4iw+E8REREREQGxkBEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSZ/BA9Ndff+Ff//oXbGxsYGFhga5duyI9PV1cLwgCIiMjoVQqYW5uDh8fH2RmZuq8hlarxfTp09G8eXM0adIEgYGByMnJ0akpKChASEgI5HI55HI5QkJCUFhYWBubSERERHXccweioqIi7Nu3D1lZWXo/t6CgAD179oSJiQm+/fZbnD9/Hp988gmaNm0q1ixduhTLli1DbGws0tLSoFAo4Ofnh+LiYrEmPDwce/fuRXx8PJKTk3Hnzh0EBASgrKxMrAkODkZGRgYSEhKQkJCAjIwMhISEPNe2ExERUcMgEwRB0OcJQUFBeO211zBt2jRoNBp06dIFf/75JwRBQHx8PIYPH17l15o3bx6OHz+On3766YnrBUGAUqlEeHg45s6dC+DhaJC9vT2WLFmCyZMnQ61Ww9bWFtu2bcPIkSMBANevX4eDgwMOHTqE/v37IysrC66urkhJSYGnpycAICUlBV5eXrhw4QKcnZ0rvbdWq4VWqxV/LioqgoODA9RqNaysrKq8jUREVH/IomSGbkGyhEV6xZEqKyoqglwu/8fPb71HiH788Uf06tULALB3714IgoDCwkJ8+umn+PDDD/V6ra+//hrdu3fHm2++CTs7O7z00kvYsGGDuP7KlStQqVTo16+fuMzMzAy9e/fGiRMnAADp6em4f/++To1SqYSbm5tYc/LkScjlcjEMAUCPHj0gl8vFmsfFxMSIh9fkcjkcHBz02jYiIiKqP/QORGq1GtbW1gCAhIQEDB8+HBYWFhg0aBAuXbqk12tdvnwZa9asgZOTEw4fPox33nkHYWFh2Lp1KwBApVIBAOzt7XWeZ29vL65TqVQwNTVFs2bNnlpjZ2dX6f3t7OzEmsfNnz8farVafGRnZ+u1bURERFR/GOv7BAcHB5w8eRLW1tZISEhAfHw8gIfnAzVu3Fiv1yovL0f37t0RHR0NAHjppZeQmZmJNWvW4K233hLrZDLdIUxBECote9zjNU+qf9rrmJmZwczMrMrbQkRERPWX3iNE4eHhGDNmDFq1agWlUgkfHx8ADw+lubu76/VaLVq0gKurq84yFxcXXLt2DQCgUCgAoNIoTl5enjhqpFAoUFpaioKCgqfW3Lhxo9L737x5s9LoExEREUmP3oFoypQpOHnyJD7//HMkJyfDyOjhS7Rt21bvc4h69uyJixcv6iz77bff0Lp1awCAo6MjFAoFjh49Kq4vLS1FUlISvL29AQAeHh4wMTHRqcnNzcW5c+fEGi8vL6jVaqSmpoo1p06dglqtFmuIiIhIuvQ+ZAYA3bt3R/fu3XWWDRo0SO/XmTlzJry9vREdHY2goCCkpqZi/fr1WL9+PYCHh7nCw8MRHR0NJycnODk5ITo6GhYWFggODgYAyOVyhIaGIiIiAjY2NrC2tsbs2bPh7u6Ovn37Ang46jRgwABMnDgR69atAwBMmjQJAQEBT7zCjIiIiKRF70BUVlaGuLg4HDt2DHl5eSgvL9dZ/91331X5tV5++WXs3bsX8+fPxwcffABHR0esWLECY8aMEWvmzJkDjUaDKVOmoKCgAJ6enjhy5AgsLS3FmuXLl8PY2BhBQUHQaDTw9fVFXFwcGjVqJNbs2LEDYWFh4tVogYGBiI2N1XfziYiIqAHSex6iadOmIS4uDoMGDUKLFi0qnZS8fPnyam2wrqjqPAZERFR/cR4iwzH0PER6jxDFx8fjyy+/xMCBA5+rQSIiIqK6Qu+Tqk1NTdG+ffua6IWIiIjIIPQORBEREVi5ciX0PNJGREREVGfpfcgsOTkZ33//Pb799lt06tQJJiYmOuv37NlTbc0RERER1Qa9A1HTpk0xdOjQmuiFiIiIyCD0DkSbN2+uiT6IiIiIDOaZJmYEHt724uLFi5DJZOjQoQNsbW2rsy8iIiKiWqP3SdUlJSUYP348WrRogddeew29evWCUqlEaGgo7t69WxM9EhEREdUovQPRrFmzkJSUhAMHDqCwsBCFhYXYv38/kpKSEBERURM9EhEREdUovQ+Z7d69G1999ZV4l3sAGDhwIMzNzREUFIQ1a9ZUZ39ERERENU7vEaK7d+/C3t6+0nI7OzseMiMiIqJ6Se9A5OXlhUWLFuHevXviMo1Gg6ioKHh5eVVrc0RERES1Qe9DZitXrsSAAQPQqlUrdOnSBTKZDBkZGWjcuDEOHz5cEz0SERER1Si9A5GbmxsuXbqE7du348KFCxAEAaNGjcKYMWNgbm5eEz0SERER1ahnmofI3NwcEydOrO5eiIiIiAyiSoHo66+/hr+/P0xMTPD1118/tTYwMLBaGiMiIiKqLVUKREOGDIFKpYKdnR2GDBnyt3UymQxlZWXV1RsRERFRrahSICovL3/iv4mIiIgaAr0vu9+6dSu0Wm2l5aWlpdi6dWu1NEVERERUm/QOROPGjYNara60vLi4GOPGjauWpoiIiIhqk96BSBAEyGSySstzcnIgl8urpSkiIiKi2lTly+5feuklyGQyyGQy+Pr6wtj4/55aVlaGK1euYMCAATXSJBEREVFNqnIgqri6LCMjA/3798cLL7wgrjM1NUWbNm0wfPjwam+QiIiIqKZVORAtWrQIANCmTRuMHDkSjRs3rrGmiIiIiGqT3jNVjx07tib6ICIiIjIYvQNRWVkZli9fji+//BLXrl1DaWmpzvrbt29XW3NEREREtUHvq8yioqKwbNkyBAUFQa1WY9asWRg2bBiMjIwQGRlZAy0SERER1Sy9A9GOHTuwYcMGzJ49G8bGxhg9ejQ2btyIhQsXIiUlpSZ6JCIiIqpRegcilUoFd3d3AMALL7wgTtIYEBCAgwcPVm93RERERLVA70DUqlUr5ObmAgDat2+PI0eOAADS0tJgZmZWvd0RERER1QK9A9HQoUNx7NgxAMCMGTPw/vvvw8nJCW+99RbGjx+v12tFRkaKkz1WPBQKhbheEARERkZCqVTC3NwcPj4+yMzM1HkNrVaL6dOno3nz5mjSpAkCAwORk5OjU1NQUICQkBDI5XLI5XKEhISgsLBQ300nIiKiBkrvq8w++ugj8d8jRoyAg4MDjh8/jvbt2yMwMFDvBjp16oTExETx50aNGon/Xrp0KZYtW4a4uDh06NABH374Ifz8/HDx4kVYWloCAMLDw3HgwAHEx8fDxsYGERERCAgIQHp6uvhawcHByMnJQUJCAgBg0qRJCAkJwYEDB/Tul4iIiBoevQPR3bt3YWFhIf7s6ekJT0/PZ2/A2FhnVKiCIAhYsWIF3nvvPQwbNgwAsGXLFtjb22Pnzp2YPHky1Go1Nm3ahG3btqFv374AgO3bt8PBwQGJiYno378/srKykJCQgJSUFLHPDRs2wMvLCxcvXoSzs/Mz905EREQNg96HzOzs7PCvf/0Lhw8fRnl5+XM3cOnSJSiVSjg6OmLUqFG4fPkyAODKlStQqVTo16+fWGtmZobevXvjxIkTAID09HTcv39fp0apVMLNzU2sOXnyJORyuU5o69GjB+RyuVjzJFqtFkVFRToPIiIiapj0DkRbt26FVqvF0KFDoVQqMWPGDKSlpT3Tm3t6emLr1q04fPgwNmzYAJVKBW9vb9y6dQsqlQoAYG9vr/Mce3t7cZ1KpYKpqSmaNWv21Bo7O7tK721nZyfWPElMTIx4zpFcLoeDg8MzbSMRERHVfXoHomHDhmHXrl24ceMGYmJikJWVBW9vb3To0AEffPCBXq/l7++P4cOHw93dHX379hUv29+yZYtYI5PJdJ4jCEKlZY97vOZJ9f/0OvPnz4darRYf2dnZVdomIiIiqn/0DkQVLC0tMW7cOBw5cgS//PILmjRpgqioqOdqpkmTJnB3d8elS5fE84oeH8XJy8sTR40UCgVKS0tRUFDw1JobN25Ueq+bN29WGn16lJmZGaysrHQeRERE1DA9cyC6d+8evvzySwwZMgTdunXDrVu3MHv27OdqRqvVIisrCy1atICjoyMUCgWOHj0qri8tLUVSUhK8vb0BAB4eHjAxMdGpyc3Nxblz58QaLy8vqNVqpKamijWnTp2CWq0Wa4iIiEja9L7K7MiRI9ixYwf27duHRo0aYcSIETh8+DB69+6t95vPnj0bgwcPxosvvoi8vDx8+OGHKCoqwtixYyGTyRAeHo7o6Gg4OTnByckJ0dHRsLCwQHBwMABALpcjNDQUERERsLGxgbW1NWbPni0eggMAFxcXDBgwABMnTsS6desAPLzsPiAggFeYEREREYBnCERDhgxBQEAAtmzZgkGDBsHExOSZ3zwnJwejR49Gfn4+bG1t0aNHD6SkpKB169YAgDlz5kCj0WDKlCkoKCiAp6cnjhw5Is5BBADLly+HsbExgoKCoNFo4Ovri7i4OJ35jHbs2IGwsDDxarTAwEDExsY+c99ERETUsMgEQRCqWvzgwQOsXr0ab775Jlq0aFGTfdU5RUVFkMvlUKvVPJ+IiKiBkkU9/aIdqjnCoirHEb1U9fNbr3OIjI2NMW/ePJSWlj53g0RERER1hd4nVXt6euLnn3+uiV6IiIiIDELvc4imTJmCiIgI5OTkwMPDA02aNNFZ37lz52prjoiIiKg26B2IRo4cCQAICwsTl8lkMnGiw7KysurrjoiIiKgW6B2Irly5UhN9EBERERmM3oGo4pJ4IiIioobimWaq3rZtG3r27AmlUomrV68CAFasWIH9+/dXa3NEREREtUHvQLRmzRrMmjULAwcORGFhoXjOUNOmTbFixYrq7o+IiIioxukdiD777DNs2LAB7733ns5s0N27d8fZs2ertTkiIiKi2qB3ILpy5QpeeumlSsvNzMxQUlJSLU0RERER1Sa9A5GjoyMyMjIqLf/222/h6upaHT0RERER1Sq9rzJ79913MXXqVNy7dw+CICA1NRVffPEFYmJisHHjxprokYiIiKhG6R2Ixo0bhwcPHmDOnDm4e/cugoOD0bJlS6xcuRKjRo2qiR6JiIiIapTegQgAJk6ciIkTJyI/Px/l5eWws7Or7r6IiIiIao3e5xBpNBrcvXsXANC8eXNoNBqsWLECR44cqfbmiIiIiGqD3oHojTfewNatWwEAhYWFeOWVV/DJJ5/gjTfewJo1a6q9QSIiIqKapncgOnPmDHr16gUA+Oqrr6BQKHD16lVs3boVn376abU3SERERFTT9A5Ed+/ehaWlJQDgyJEjGDZsGIyMjNCjRw/xNh5ERERE9Ynegah9+/bYt28fsrOzcfjwYfTr1w8AkJeXBysrq2pvkIiIiKim6R2IFi5ciNmzZ6NNmzZ45ZVX4OXlBeDhaNGTZrAmIiIiquv0vux+xIgRePXVV5Gbm4suXbqIy319fTF06NBqbY6IiIioNjzTPEQKhQIKhQLZ2dmQyWRo1aoVXnnllerujYiIiKhW6H3I7MGDB3j//fchl8vRpk0btG7dGnK5HAsWLMD9+/drokciIiKiGqX3CNG0adOwd+9eLF26VDx/6OTJk4iMjER+fj7Wrl1b7U0SERER1SS9A9EXX3yB+Ph4+Pv7i8s6d+6MF198EaNGjWIgIiIionpH70NmjRs3Rps2bSotb9OmDUxNTaujJyIiIqJapXcgmjp1Kv7zn/9Aq9WKy7RaLRYvXoxp06ZVa3NEREREtaFKh8yGDRum83NiYiJatWolXnb/yy+/oLS0FL6+vtXfIREREVENq1IgksvlOj8PHz5c52cHB4fq64iIiIiollUpEG3evLmm+yAiIiIyGL3PIapw8+ZNJCcn4/jx47h58+ZzNxITEwOZTIbw8HBxmSAIiIyMhFKphLm5OXx8fJCZmanzPK1Wi+nTp6N58+Zo0qQJAgMDkZOTo1NTUFCAkJAQyOVyyOVyhISEoLCw8Ll7JiIiooZB70BUUlKC8ePHo0WLFnjttdfQq1cvKJVKhIaG4u7du8/URFpaGtavX4/OnTvrLF+6dCmWLVuG2NhYpKWlQaFQwM/PD8XFxWJNeHg49u7di/j4eCQnJ+POnTsICAhAWVmZWBMcHIyMjAwkJCQgISEBGRkZCAkJeaZeiYiIqOHROxDNmjULSUlJOHDgAAoLC1FYWIj9+/cjKSkJERERejdw584djBkzBhs2bECzZs3E5YIgYMWKFXjvvfcwbNgwuLm5YcuWLbh79y527twJAFCr1di0aRM++eQT9O3bFy+99BK2b9+Os2fPIjExEQCQlZWFhIQEbNy4EV5eXvDy8sKGDRvwzTff4OLFi3r3S0RERA2P3oFo9+7d2LRpE/z9/WFlZQUrKysMHDgQGzZswFdffaV3A1OnTsWgQYPQt29fneVXrlyBSqVCv379xGVmZmbo3bs3Tpw4AQBIT0/H/fv3dWqUSiXc3NzEmpMnT0Iul8PT01Os6dGjB+RyuVjzJFqtFkVFRToPIiIiapj0nqn67t27sLe3r7Tczs5O70Nm8fHxOHPmDNLS0iqtU6lUAFDpvezt7XH16lWxxtTUVGdkqaKm4vkqlQp2dnZP7Lei5kliYmIQFRWl1/YQERFR/aT3CJGXlxcWLVqEe/fuics0Gg2ioqLEe5tVRXZ2NmbMmIHt27ejcePGf1snk8l0fhYEodKyxz1e86T6f3qd+fPnQ61Wi4/s7OynvicRERHVX3qPEK1cuRIDBgwQJ2aUyWTIyMhA48aNcfjw4Sq/Tnp6OvLy8uDh4SEuKysrw48//ojY2Fjx/B6VSoUWLVqINXl5eeKokUKhQGlpKQoKCnRGifLy8uDt7S3W3Lhxo9L737x584kjXRXMzMxgZmZW5e0hIiKi+kvvESI3NzdcunQJMTEx6Nq1Kzp37oyPPvoIly5dQqdOnar8Or6+vjh79iwyMjLER/fu3TFmzBhkZGSgbdu2UCgUOHr0qPic0tJSJCUliWHHw8MDJiYmOjW5ubk4d+6cWOPl5QW1Wo3U1FSx5tSpU1Cr1WINERERSZveI0QAYG5ujokTJz7XG1taWsLNzU1nWZMmTWBjYyMuDw8PR3R0NJycnODk5ITo6GhYWFggODgYwMMZtENDQxEREQEbGxtYW1tj9uzZcHd3F0/SdnFxwYABAzBx4kSsW7cOADBp0iQEBATA2dn5ubaBiIiIGoZnCkS1Zc6cOdBoNJgyZQoKCgrg6emJI0eOwNLSUqxZvnw5jI2NERQUBI1GA19fX8TFxaFRo0ZizY4dOxAWFiZejRYYGIjY2Nha3x4iIiKqm2SCIAiGbqI+KCoqglwuh1qthpWVlaHbISKiGiCLevpFO1RzhEU1E0eq+vn9zLfuICIiImooqhSIPv30U/Ey+2vXroGDSkRERNSQVCkQzZo1S5yp2dHRsVpu5kpERERUV1TppGqlUondu3dj4MCBEAQBOTk5OhMzPurFF1+s1gaJiIiIalqVAtGCBQswffp0TJs2DTKZDC+//HKlmoqZnx+9yzwRERFRfVClQDRp0iSMHj0aV69eRefOnZGYmAgbG5ua7o2IiIioVlR5HqKKiRQ3b96Mnj178rYWRERE1GDoPTHj2LFjATy8F1lWVhZkMhlcXFzQrVu3am+OiIiIqDboHYjy8vIwatQo/PDDD2jatCkEQYBarcbrr7+O+Ph42Nra1kSfRER1CifwM5yamsCPpE3viRmnT5+OoqIiZGZm4vbt2ygoKMC5c+dQVFSEsLCwmuiRiIiIqEbpPUKUkJCAxMREuLi4iMtcXV2xatUq8V5hRERERPWJ3iNE5eXlMDExqbTcxMQE5eXl1dIUERERUW3SOxD16dMHM2bMwPXr18Vlf/31F2bOnAlfX99qbY6IiIioNugdiGJjY1FcXIw2bdqgXbt2aN++PRwdHVFcXIzPPvusJnokIiIiqlF6n0Pk4OCAM2fO4OjRo7hw4QIEQYCrqyv69u1bE/0RERER1Ti9A1EFPz8/+Pn5VWcvRERERAah9yEzIiIiooaGgYiIiIgkj4GIiIiIJI+BiIiIiCSPgYiIiIgkr9oCUd++fdG2bdvqejkiIiKiWvPMl90/bujQocjPz6+ulyMiIiKqNdUWiKZOnVpdL0VERERUq545EKWnpyMrKwsymQwuLi7o1q1bdfZFREREVGv0DkR5eXkYNWoUfvjhBzRt2hSCIECtVuP1119HfHw8bG1ta6JPIiIiohqj90nV06dPR1FRETIzM3H79m0UFBTg3LlzKCoqQlhYWE30SERERFSj9B4hSkhIQGJiIlxcXMRlrq6uWLVqFfr161etzRERERHVBr1HiMrLy2FiYlJpuYmJCcrLy6ulKSIiIqLapHcg6tOnD2bMmIHr16+Ly/766y/MnDkTvr6+1docERERUW3QOxDFxsaiuLgYbdq0Qbt27dC+fXs4OjqiuLgYn332mV6vtWbNGnTu3BlWVlawsrKCl5cXvv32W3G9IAiIjIyEUqmEubk5fHx8kJmZqfMaWq0W06dPR/PmzdGkSRMEBgYiJydHp6agoAAhISGQy+WQy+UICQlBYWGhvptOREREDZTegcjBwQFnzpzBwYMHER4ejrCwMBw6dAjp6elo1aqVXq/VqlUrfPTRRzh9+jROnz6NPn364I033hBDz9KlS7Fs2TLExsYiLS0NCoUCfn5+KC4uFl8jPDwce/fuRXx8PJKTk3Hnzh0EBASgrKxMrAkODkZGRgYSEhKQkJCAjIwMhISE6LvpRERE1EDJBEEQDN3Eo6ytrfHxxx9j/PjxUCqVCA8Px9y5cwE8HA2yt7fHkiVLMHnyZKjVatja2mLbtm0YOXIkAOD69etwcHDAoUOH0L9/f2RlZcHV1RUpKSnw9PQEAKSkpMDLywsXLlyAs7NzlfoqKiqCXC6HWq2GlZVVzWw8EdUbsiiZoVuQLGFRzX1scb8aTk3t16p+fj/TxIzHjh3DsWPHkJeXV+lE6s8///xZXhJlZWXYtWsXSkpK4OXlhStXrkClUulcuWZmZobevXvjxIkTmDx5MtLT03H//n2dGqVSCTc3N5w4cQL9+/fHyZMnIZfLxTAEAD169IBcLseJEyf+NhBptVpotVrx56KiomfaLiIiIqr79D5kFhUVhX79+uHYsWPIz89HQUGBzkNfZ8+exQsvvAAzMzO888472Lt3L1xdXaFSqQAA9vb2OvX29vbiOpVKBVNTUzRr1uypNXZ2dpXe187OTqx5kpiYGPGcI7lcDgcHB723jYiIiOoHvUeI1q5di7i4uGo7B8fZ2RkZGRkoLCzE7t27MXbsWCQlJYnrZTLd4UtBECote9zjNU+q/6fXmT9/PmbNmiX+XFRUxFBERETUQOk9QlRaWgpvb+9qa8DU1BTt27dH9+7dERMTgy5dumDlypVQKBQAUGkUJy8vTxw1UigUKC0trTQy9XjNjRs3Kr3vzZs3K40+PcrMzEy8+q3iQURERA2T3oFowoQJ2LlzZ030AuDhyI1Wq4WjoyMUCgWOHj0qristLUVSUpIYyDw8PGBiYqJTk5ubi3Pnzok1Xl5eUKvVSE1NFWtOnToFtVpdrcGOiIiI6i+9D5ndu3cP69evR2JiIjp37lxp1uply5ZV+bX+/e9/w9/fHw4ODiguLkZ8fDx++OEHJCQkQCaTITw8HNHR0XBycoKTkxOio6NhYWGB4OBgAIBcLkdoaCgiIiJgY2MDa2trzJ49G+7u7ujbty8AwMXFBQMGDMDEiROxbt06AMCkSZMQEBBQ5SvMiIiIqGHTOxD9+uuv6Nq1KwDg3LlzOuv+6dyex924cQMhISHIzc2FXC5H586dkZCQAD8/PwDAnDlzoNFoMGXKFBQUFMDT0xNHjhyBpaWl+BrLly+HsbExgoKCoNFo4Ovri7i4ODRq1Eis2bFjB8LCwsSr0QIDAxEbG6vvphMREVEDVefmIaqrOA8RET2K89UYDuchapgMPQ+R3ucQERERETU0DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkecaGboCoIZNFyQzdgmQJiwRDt0BE9QhHiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyDBqIYmJi8PLLL8PS0hJ2dnYYMmQILl68qFMjCAIiIyOhVCphbm4OHx8fZGZm6tRotVpMnz4dzZs3R5MmTRAYGIicnBydmoKCAoSEhEAul0MulyMkJASFhYU1vYlERERUDxg0ECUlJWHq1KlISUnB0aNH8eDBA/Tr1w8lJSVizdKlS7Fs2TLExsYiLS0NCoUCfn5+KC4uFmvCw8Oxd+9exMfHIzk5GXfu3EFAQADKysrEmuDgYGRkZCAhIQEJCQnIyMhASEhIrW4vERER1U0yQRDqzB0Qb968CTs7OyQlJeG1116DIAhQKpUIDw/H3LlzATwcDbK3t8eSJUswefJkqNVq2NraYtu2bRg5ciQA4Pr163BwcMChQ4fQv39/ZGVlwdXVFSkpKfD09AQApKSkwMvLCxcuXICzs/M/9lZUVAS5XA61Wg0rK6ua+49ADQpv7mo4NX1zV+5bw6nJfcv9ajg1tV+r+vldp84hUqvVAABra2sAwJUrV6BSqdCvXz+xxszMDL1798aJEycAAOnp6bh//75OjVKphJubm1hz8uRJyOVyMQwBQI8ePSCXy8Wax2m1WhQVFek8iIiIqGGqM4FIEATMmjULr776Ktzc3AAAKpUKAGBvb69Ta29vL65TqVQwNTVFs2bNnlpjZ2dX6T3t7OzEmsfFxMSI5xvJ5XI4ODg83wYSERFRnVVnAtG0adPw66+/4osvvqi0TibTHcIUBKHSssc9XvOk+qe9zvz586FWq8VHdnZ2VTaDiIiI6qE6EYimT5+Or7/+Gt9//z1atWolLlcoFABQaRQnLy9PHDVSKBQoLS1FQUHBU2tu3LhR6X1v3rxZafSpgpmZGaysrHQeRERE1DAZNBAJgoBp06Zhz549+O677+Do6Kiz3tHREQqFAkePHhWXlZaWIikpCd7e3gAADw8PmJiY6NTk5ubi3LlzYo2XlxfUajVSU1PFmlOnTkGtVos1REREJF3GhnzzqVOnYufOndi/fz8sLS3FkSC5XA5zc3PIZDKEh4cjOjoaTk5OcHJyQnR0NCwsLBAcHCzWhoaGIiIiAjY2NrC2tsbs2bPh7u6Ovn37AgBcXFwwYMAATJw4EevWrQMATJo0CQEBAVW6woyIiIgaNoMGojVr1gAAfHx8dJZv3rwZb7/9NgBgzpw50Gg0mDJlCgoKCuDp6YkjR47A0tJSrF++fDmMjY0RFBQEjUYDX19fxMXFoVGjRmLNjh07EBYWJl6NFhgYiNjY2JrdQCIiIqoX6tQ8RHUZ5yGiZ8E5TQyH8xA1XJyHqGHiPEREREREBsZARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREksdARERERJLHQERERESSx0BEREREkmds6AYIkEXJDN2CZAmLBEO3QEREdQBHiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyGIiIiIhI8hiIiIiISPIYiIiIiEjyDBqIfvzxRwwePBhKpRIymQz79u3TWS8IAiIjI6FUKmFubg4fHx9kZmbq1Gi1WkyfPh3NmzdHkyZNEBgYiJycHJ2agoIChISEQC6XQy6XIyQkBIWFhTW8dURERFRfGDQQlZSUoEuXLoiNjX3i+qVLl2LZsmWIjY1FWloaFAoF/Pz8UFxcLNaEh4dj7969iI+PR3JyMu7cuYOAgACUlZWJNcHBwcjIyEBCQgISEhKQkZGBkJCQGt8+IiIiqh8MOlO1v78//P39n7hOEASsWLEC7733HoYNGwYA2LJlC+zt7bFz505MnjwZarUamzZtwrZt29C3b18AwPbt2+Hg4IDExET0798fWVlZSEhIQEpKCjw9PQEAGzZsgJeXFy5evAhnZ+fa2VgiIiKqs+rsOURXrlyBSqVCv379xGVmZmbo3bs3Tpw4AQBIT0/H/fv3dWqUSiXc3NzEmpMnT0Iul4thCAB69OgBuVwu1jyJVqtFUVGRzoOIiIgapjobiFQqFQDA3t5eZ7m9vb24TqVSwdTUFM2aNXtqjZ2dXaXXt7OzE2ueJCYmRjznSC6Xw8HB4bm2h4iIiOquOhuIKshkujc+FQSh0rLHPV7zpPp/ep358+dDrVaLj+zsbD07JyIiovqizgYihUIBAJVGcfLy8sRRI4VCgdLSUhQUFDy15saNG5Ve/+bNm5VGnx5lZmYGKysrnQcRERE1THU2EDk6OkKhUODo0aPistLSUiQlJcHb2xsA4OHhARMTE52a3NxcnDt3Tqzx8vKCWq1GamqqWHPq1Cmo1WqxhoiIiKTNoFeZ3blzB7///rv485UrV5CRkQFra2u8+OKLCA8PR3R0NJycnODk5ITo6GhYWFggODgYACCXyxEaGoqIiAjY2NjA2toas2fPhru7u3jVmYuLCwYMGICJEydi3bp1AIBJkyYhICCAV5gRERERAAMHotOnT+P1118Xf541axYAYOzYsYiLi8OcOXOg0WgwZcoUFBQUwNPTE0eOHIGlpaX4nOXLl8PY2BhBQUHQaDTw9fVFXFwcGjVqJNbs2LEDYWFh4tVogYGBfzv3EREREUmPTBAEwdBN1AdFRUWQy+VQq9XVfj6RLOrpJ4lTzREW1ez//blvDYf7tuGqyX3L/Wo4NbVfq/r5XWfPISIiIiKqLQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5DEREREQkeQxEREREJHkMRERERCR5kgpEq1evhqOjIxo3bgwPDw/89NNPhm6JiIiI6gDJBKL//e9/CA8Px3vvvYeff/4ZvXr1gr+/P65du2bo1oiIiMjAJBOIli1bhtDQUEyYMAEuLi5YsWIFHBwcsGbNGkO3RkRERAZmbOgGakNpaSnS09Mxb948neX9+vXDiRMnnvgcrVYLrVYr/qxWqwEARUVF1d/gvep/SaqaGtmfj+K+NRju24arRvct96vB1NR+rXhdQRCeWieJQJSfn4+ysjLY29vrLLe3t4dKpXric2JiYhAVFVVpuYODQ430SIYh/0hu6BaohnDfNlzctw1TTe/X4uJiyOV//x6SCEQVZDKZzs+CIFRaVmH+/PmYNWuW+HN5eTlu374NGxubv32OFBUVFcHBwQHZ2dmwsrIydDtUTbhfGy7u24aL+/bJBEFAcXExlErlU+skEYiaN2+ORo0aVRoNysvLqzRqVMHMzAxmZmY6y5o2bVpTLdZ7VlZW/AVsgLhfGy7u24aL+7ayp40MVZDESdWmpqbw8PDA0aNHdZYfPXoU3t7eBuqKiIiI6gpJjBABwKxZsxASEoLu3bvDy8sL69evx7Vr1/DOO+8YujUiIiIyMMkEopEjR+LWrVv44IMPkJubCzc3Nxw6dAitW7c2dGv1mpmZGRYtWlTp8CLVb9yvDRf3bcPFfft8ZMI/XYdGRERE1MBJ4hwiIiIioqdhICIiIiLJYyAiIiIiyWMgIiIiIsljICIiIiLJYyCiGsWLGImIqD5gIKIa9eh938rLyw3YCRGRNFR8EX30f/nl9J9JZmJGql1JSUk4c+YMPD09UVpaiq5du/JecBJRVlaGRo0aGboNqgbcl/WTTCbDrVu3YGNjg+LiYlhaWuqsf9qNzaWMEzNStbt16xYmTpwIQRBw7tw5ODg44Pfff8eQIUMQEREhzg7OX8qG4eDBg2jbti0AoGXLlrypZD2WlpaGDh064O7du2jRooWh26FnFB8fj3//+99o3749jIyM0KpVK4wdOxbt2rX7xzu+SxkDEdUIjUYDc3Nz3Lp1C+fOncP58+fx2WefITs7G++//z7mzJlj6BapGuzZswerV6/Gzz//jO7du+PSpUvw9fXFO++8g44dO6JJkyaGbpGq6NChQ4iJicH58+fh7e2N69evY8SIERg9ejSUSiVMTU0N3SJVUVpaGpo2bYoff/wRWq0WO3fuRFpaGvz8/BASEgJ/f39YWVmhvLwcRkY8c6YCAxFVu4pfssd/2TQaDdavX4+FCxfCx8cHq1evRsuWLQ3YKT2voqIiWFlZ4ebNm8jIyEBOTg5WrVqFX3/9FSEhIYiMjISDgwPKy8shk8k4IliH5eTkwMrKCn/++ScyMzNx6dIlrFu3DhqNBtOnT0dYWBhsbGx4GK2eOn36NN5//32cPn0a06ZNw6JFiwBwpP5RDERUI572S3bs2DF8/PHH8PT0RFRUVC13RtWlYh8/6QPym2++wbRp02BkZIRdu3bBw8PDQF2SPp70e7ty5UosWLAA7u7u2L17Nw+l1XEV+/DRffnol9O4uDhMnToVgwcPxoYNGyqdXyRlHCujalGRq+/evQvg/64ue1Le7tOnD8aNG4dVq1Zh1apVtdckVauKffxoGHrw4AEEQUBAQADOnz+PHj16YNy4cfjpp58A8ErDuu5JV4XOmDEDFy9eROPGjTFw4ECkp6frrKe65Ul/e42MjFBWVgYAePvtt3Hs2DHk5+fjq6++MkiPdRVHiKhazZw5E97e3ujTpw9sbGyeWrtr1y7s27cPq1evhlwur6UO6XlVfPM8e/YsfvrpJ9y5cwfNmjXDxIkTxZr79+/DxMQE165dw8KFC3H//n3s2LHDgF3Tk1Tsy5KSEvz6668wMzODtbU12rRpI9ZUjC5cunQJCxcuhK2tLT799FPDNU2VPLqP8vPz4eXlBeD/QtHjo35lZWVYt24dPvjgA+zbtw89evSo9Z7rJIHoOZWVlQmCIAgffPCBIJPJBBcXF2HmzJnCTz/9JGg0GrGuvLxc53m3bt0S1q5dK9y5c6dW+6VnV7GvExMTBVdXV8HBwUF4/fXXBYVCIdja2gqxsbGVnvPXX38J3bp1E5YvX17p/wNkOBX74vz588LQoUOFxo0bC46OjsJbb70l5OfnP/E5P//8s+Do6CisWrWK+7IO6tatm+Ds7Cy8//77wuXLl8XlFb+3j4uNjRUOHTpUW+3VeRwhompRXFwMPz8/BAUFoVGjRli1ahUsLS0xcuRIDBw4EG5ubgAeHlJLSEjA0KFDeSJfPdaxY0eMHDkS8+fPR2lpKf766y9s27YNK1euROfOnbF9+3a0a9dO/OZ6/Phx5OXlYejQoYZunR7To0cPdOzYEVOnTkVeXh7eeecd+Pv7Y/369WKN8Mj5KEePHsXt27cxcuRIQ7VMj6jYNzt37sTs2bPh5+eHP/74AxYWFhgyZAjGjh2rc7XngwcPYGz8cArCW7duoaSkBC+++KKh2q9bDJvHqKG4evWqMHPmTGHPnj2CIAjC7du3henTpwstW7YU+vXrJ2zZskW4fv268Mknnwht27Y1cLf0PC5evCh07NhROHXqlM7y8vJyISUlRejdu7cwYMCASqMMj44WkmFVjO7s27dPaN26tXD79m1x3b59+4TOnTsLhYWF4rLS0lLx32VlZTrryPDKysqEyZMnC2PHjhVu3LghfP3118KYMWMET09P4c033xT2798v1vbs2VM4ePCgAbutuzhCRNWivLwcOTk5aN68OSwsLMTlv/zyC95//31kZGTA09MTe/fuxfr16zF+/HjOgVFPFRUVoWvXrnjzzTexZMmSSuuTkpIQGBiIdevWYdSoUdzPddjcuXNRXFyM//73vzA3N4dMJoNKpYKnpyd27NiBV199FQDw3nvvwcXFBf/6178M3DE9Tvj/R4guX76MM2fOYMSIEQAejv7s2rULBw8eRH5+Pl5++WXI5XIsXrwYxcXFnCPsCRiIqEZUXIFS8UG4b98+jBgxAj179kRSUpIhW6PnUPHHd82aNVi2bBnCwsIwcuRI2NnZ6dSNHj0aHTp04LQKdVDFPtRqtdixYweuXbuGyMhIAP93cu6QIUPQokULrFmzBsnJyXjttdeQk5PDWY7rmNu3b8Pa2rrS8kcPi/3222/YuXMnvvvuOyQnJ2PFihUICwvTqaGH+LWNaoSRkZHOpZ4dOnSAIAhYvnw5gCdfjk9115kzZ5CTkyPObzJ06FC89tprWLduHaKjo3Hs2DGUlJQAePjNNC0tDba2tgC4r+uaq1evQqvVwszMDOPHj8eMGTMAPNxPFV9gRo8ejfT0dAiCgFmzZmHatGlQKpW81L6O6d+/vzh1ScXfWgAwNjYWf+86dOiAyMhIKBQKODs7IywsTKwhXRwhompTMUFffn4+SkpKdO5ZNm/ePPzyyy9ISEjgIZR6aM6cOSgqKsLatWt1lq9cuRJr1qyBXC6HtbU1zMzMoFarcevWLfz6668G6paepmJ0YPXq1QCefAPXs2fPYty4cRg8eDCWL1+OwsJCA3RK/yQ+Ph4HDhzAunXr8MILLwCoPLmmIAj4/fff4ezsjK+//hoBAQEcHfob/FQivVVk6Me/LVb8UQ0JCcGPP/4oLpfJZIiOjsaBAwfEn6l+CQoKQmJios6VR8DDSfuOHz+OESNGwMnJCaWlpXjzzTexb98+AJy8ry4aNWoUkpOT8e233wLAE2/D0a5dO5SUlCAqKgqxsbEAdEcgqG7w9fXFn3/+iddeew1nz54FAHEUt4JMJoOlpSUWL16MgIAACILAMPQ3OEJEejt//jzs7e11Jl6s+Ja5bds2vPvuu/j1118rnVdC9dvWrVvx8ccfY+rUqQgODq50V3uO/NUfH330ETZv3oxFixZhxIgRT7xxa1RUFE6fPi1+kaG6Sa1WY9KkSSgrK8Pbb78NX19fmJubA3j4d9nIyKjSDOT8PX0yBiLS26xZs6DRaLBmzRoAukO0LVq0wJw5czBz5kxDtkjV5NE/niUlJYiOjsbhw4cxcuRIjBw5Eq1atRLXVwzD8w9u3SU8MjN1xY0+3377bQwePFg85+tRN2/ehK2tLW8AWkdV7JfvvvsO0dHRKC4uxpAhQ9CrVy94e3vz91BPDESkt1OnTuGtt97CokWLEBwcrLPuzJkz6NKlC++G3QBcvnwZBw4cwMCBA+Hk5ATgYUCKiorCf//7X3Tv3h1vv/02XF1d4enpaeBuSV+3bt3CvHnzsHPnTgwePBhjxoyBs7MzOnToYOjWqAoeD6m3b99GZGQkjh07Bnt7e5iYmMDf3x9ubm548OAB+vfvz1D7DxiI6JmsXbsWn376KSIiIjBq1CjOadEAffTRR4iMjMTgwYPx5ptv4tVXXxUvu/7jjz8wa9YsXLp0CS1atEBxcTH69+8PIyMjBAQE4OWXXzZw9/S4isPaBQUFuH//vnhI+4cffkBERAQ0Gg3atGkDU1NTvPHGGygpKYG/vz/atWtn4M7p72i1WuTl5UGr1aJ9+/YAgMzMTHz//ffIzc3FwYMH0apVK8jlcowbNw59+/Y1cMd1GwMRVdmj30ju3r2LyMhI/PTTTxgzZgyGDRumM0dJxR9fDrXXbz/++CMWLVqEP//8EwMHDsTQoUPFCd4AICMjA1lZWbh16xZSUlLwyiuvoFevXnjppZcM3Dn9nfHjx6N169Z466234OjoKC7/9ttvcenSJVy9ehUZGRnw9vaGr68vfHx8DNcsVVLxt3X37t3YsGEDLl68CEEQ4ObmhtjYWJ0b8wJAfn4+mjdvzkPZVcBARFVy+fJlfP/99xg7dqx4hYJGo8GCBQuwZs0a9O7dG2PHjoWLiwu6dOli4G7peT3+x3PTpk345JNPYGxsjKCgIAwYMABdu3bl1Sr1RMWH6Jo1a7BkyRIcOnQIrq6uAB7OJt+pUyedfckvMnVTxe/l7du30aZNG8ycOROtW7eGsbExNm7ciJ9//hkrVqxAaGhopUvruU//GQMRVcm7774LmUyGpUuXIj8/H2VlZbC3twfwcJQgIiIC169fR6tWrfDgwQMMHDgQZWVlGDRoENzd3Q3cPT2rR+eo0Wg0WLRoEeLj49GuXTsEBwejT58+PKRSTwiCgNatWyMmJgZjxoxBdnY21q5di02bNuHevXuIi4vDkCFDnjgvEdUtM2bMQGZmJhITEwE83LfXr1/HJ598gtTUVOzfv1/nKmCqGgYiqrKKbyf+/v5o3bo1goOD0a1bN3FCsJMnT+LChQtQqVRIS0uDp6cnfHx8eMJtA/DoiNGFCxewYMECpKenw9nZGYsXL4aHh4eBO6R/cubMGYwdOxZxcXHw8PBAaGgoLl26hKlTp2Lv3r24f/8+du/ebeg2qQrmzp2LP/74A1999RWA/xv9SU9Ph7+/P7Zs2QJ/f38Dd1n/cLyb/tHj9yXz8/PDunXrcPr0aYwePRp9+/ZFly5d4OXlBS8vL0O2StWgYoQgNzcXX3/9NXbv3o1XX30Vbm5u8PHxQceOHfHVV1/hwIEDiI6OFmckp7rn0cMk3bp1Q+vWrREWFob8/Hy0bt0aH3zwAXx8fFBaWorVq1ejqKio0vxSVLeUl5ejR48eWLVqFfbs2YNBgwbBzMwMAODu7g47Ozuo1WoDd1k/cYSI/tbjx5xLSkqwfft2TJ48Gbdv38bChQuxb98+uLu7Izg4GL1798aLL75owI6pOr3++ut48OABXF1d8cMPP8DExAS9e/fGsGHD8Prrr+ucY8QTNuu2AwcOYPDgwUhOTsb+/fuh0WgQGRmJ5s2bA3h4T6w2bdpg3bp1PNekDqr4kvLFF1/g1KlT+Pe//42ZM2fi6tWrCAoKQs+ePdG8eXNs2bIFq1atwo0bNwzdcv0kEP2DU6dOCYIgCKNHjxYGDx6ss+7MmTPCoEGDhLZt2wpvvPGGcObMGUO0SNWkrKxMEARB+OKLL4SWLVsKeXl5giAIQtu2bQU/Pz+hZcuWQteuXYW5c+cKGRkZhmyVqujatWuCra2tsGDBAuH+/ftCWVmZuJ+zs7OFpUuXCgqFQigpKREEQRDKy8sN2S49hZubm7BhwwZBEATh+vXrwqRJkwRXV1fBzc1NMDIyEry8vIS9e/cKgiAI9+/fN2Cn9RMPmdFT7d+/H0OHDsWgQYNw+PBh5ObmAnh4gq2pqSleeuklfPPNN9i1axeio6OhUCgM3DE9j4pRnm3btmHChAmwtbVFdHQ0LCwscOTIEXz//fcYNmwYdu3ahSFDhhi2WaoSa2trLFq0CNu3b0ezZs0wa9YsAA9H9Y4fP46LFy8iNjYWFhYWHOmrgypGhzIzM9G1a1dxjq8WLVpg3bp1SE9Px61btyCTydCpUydx+hNeAfoMDJ3IqG7Lzs4WvvzyS0EmkwmNGzcWoqOjddbfvXtXEARBuHPnjris4tsn1U8ajUbYvn27cPjwYaG0tFR45ZVXhLi4OEEQHo42jBo1StizZ4+Bu6SnefDgQaVla9asEUxMTITJkyfrLM/Ozq6ttugZ5efnCz169BCaNm0qfPTRR4Zup8HiVwF6qlatWqF79+7o06cPZs+ejfXr16Ndu3bYuXMnAMDc3Bx79uxBUFCQ+Bx+w6x/Ku5kfvv2baSkpKBPnz7w9vZGSUkJjIyMcPPmTQAP75x94sQJdO/e3ZDt0lMIgoBGjRpBq9Vi1KhR+Pzzz3H16lWMHTsWP/zwA/744w9MmzYN2dnZAB7+jlPdVV5eDgsLC3h4eKBx48ZYvXo1Vq9ejatXr+rUCTwd+LnxpGp6KkEQxJMsS0tLcfr0aWzZsgW7d+9Gx44dMW7cOCxcuBDvvvsuZs6cyRMy67k+ffqgZcuW2LZtm7jsrbfewvXr19GhQwckJyfD2dkZu3bt4r6u4zZu3IhJkyYBAAYOHIgWLVrgzp07KC8vx59//gk/Pz9ERUVxzqE66kmHL/Pz8zFv3jwcPHgQr7/+OoKDg+Ht7Q1ra2sDddmwMBDRE1Uct1ar1fjjjz/QokULtGjRAgBQUFCA5ORkbNy4EZmZmfDz88OaNWsM3DE9q4p9fe/ePUycOBEzZsxA9+7dxcBz/vx5LFiwAEVFRXB1dcXixYthaWnJQFQPLFu2DD/99BOcnZ3h6uqK33//HXFxccjJyQEA3Lhx44l3uae649NPP0VCQgIePHiAtm3b4sMPP8S1a9cwY8YM5OXlwcfHB5GRkeLfZ3p2DERUScU3k8LCQgQEBODq1au4fv06hgwZgjlz5ogTLZaVleH+/fsQBAHm5uY8IbOemzlzJs6ePYsxY8Zg3LhxKCsrg5GRkRh6Hp2jhvu6frh79y6WLl2Ka9euYe7cuXB2doYgCDh48CAaN26Mvn37cl/WQRVfUlauXImPPvoIPj4+aNu2LX744QekpKRg2bJlmDFjBpYsWYLExEQcPXrU0C03DLV/2hLVF6NHjxb69OkjHD58WDh69KjQvXt3wczMTJgxY4Zw+fJl8cRNXqZb/12/fl3o0qWLIJPJhH79+gk3btwQ12m1WgN2Rvo6dOiQEBoaKmzevFmcGmHq1KmCUqkUDh06ZODuqKrKy8uFXr16Cdu2bROX5eXlCZ999pnQtm1b4auvvhIEQRBKS0sFQXjyifSkH34tIB0VJ9fevXsXRkZG+Pjjj9GvXz/07dsXaWlpWLt2LXbt2oVXXnkF69ev52GTBqC8vBxyuRxHjx5FXFwcfv/9d7i6umL9+vUAAFNTU56wWY8IgoD09HTs2LEDI0eORM+ePeHl5YXOnTtj3rx52L9/v/h7TnVPxZ0Bjh8/jubNm8POzk5cZ2triwkTJsDV1RVr166FVqsVzwHjuWDPj4GIdFT8Uv3nP/9BXl4eUlNTAfzfFQxvv/02/vzzT4wYMQLFxcUMQ/XYrVu3AABjx47FrFmzYGtri5CQEBw7dgwTJkzAzJkz0b17dyQmJnI/1yMDBw7Ezz//jNWrV2Pt2rXw8vLCf/7zH9y+fRtnz57F9u3b+eFZhxkZGeHWrVuYPXs2jh49iv/9739iSAKAxo0bY/To0cjNzYVGo+HhzmrEc4ioErVajf79+yM1NRU9e/bEhg0b0LFjRwCVb+dB9dPu3btx4MAB9O7dGxMnTkRGRgbc3NzE9Q8ePMAvv/yCDz/8EPv378dff/3FkzbrqIpzgB48eICrV68iISEBnTp1gr29PVxcXAA83J/Hjx9HdnY2Xn75ZTg7O/PcoTru1KlTWLRoEX7++WcMHz4cw4cPh6+vL/744w9MmjQJSqUS27Zt436sRgxE9LcOHDiAOXPmQKVSYf78+Zg0aRKaNm1q6LaoGqxatQrbtm1DVlYWHB0dER8fL4beR2m1Wvz+++/o1KkT//DWURX7JSIiAsnJySgoKEBRURE8PDywefNmNG/enPutniovL8fu3buxdOlSFBYWwsTERAy6q1evBvAw7HJW6urB3xIC8H/Hre/du4czZ87gt99+w+DBg3H69Gm89957iI6OxmuvvYYvvviC5x80AFOnTsW8efPQqFEjCIKAiIgIrFixAn/++adY8+OPP2LPnj3o1KkTAE64WRdVhKHU1FRs2LABixcvxm+//YbmzZujXbt2sLOzQ2FhoXiZPdUvRkZGePPNN/H999/j7bffRmFhIUxNTdGlSxdoNBoAvEVHdeIIEYmXeObl5WH8+PE4f/48rl27hgEDBiA0NBT+/v64desWFi1ahM8//xyXL19GmzZtDN02PQdBEFBQUIC//voLGo0Gn3zyCS5dugQXFxf4+/ujZ8+eePXVVxEaGooPPvjA0O3SP5gwYQKAh5Mxfvnll5g+fToyMjLQokULbNy4EXl5eQgLC8MLL7xg4E7peWRnZ2POnDm4dOkSunXrhgEDBmDo0KE8jaGaMBCReF5QYGAgysrKsGzZMly8eBFDhgyBkZERhg0bhlmzZqF79+7466+/0Lp1ax4+qacq9vWBAweQm5uL0NBQ8QTbrVu3YseOHVCpVCgpKYG9vT2OHz9u4I7paSr2Z1RUFG7cuIHVq1fD0dERU6dOxezZswEAH374IVJSUvDNN98YuFuqLsePH8c777wDf39/LF261NDtNBgMRBJX8Qc1NTVVPETm4OCAXr16wcfHBz179kRQUBAaN26MSZMm4cMPPzR0y/ScBEHAtGnT8N1336Fjx44IDQ1FQEAAgIcn1B88eBD29vZwdnZGq1atGH7rgY0bN2Lx4sXw9fXF6dOnkZGRAeDhrPKurq5Yvnw5Ro0axX3ZgNy/fx8ajUacLJWeHw8+SlzFUGtWVhaCgoLg4OCAPXv2IDc3F++88w5atmwJX19f3Lt3Dw4ODgB4pVl9J5PJ8N5776Fbt2745ptvsHDhQuzfvx8zZsyAm5sbgoODder5AVr3PP47OGHCBPz+++/YtGkT3NzccPXqVaSmpuLLL79EmzZtMGrUKADclw2JiYkJTExMDN1Gg8IRIgIAXLlyBVlZWRg4cCBmzpyJmzdvYuPGjWjcuDEWLVoEd3d3jBgxwtBt0jP6uxCbmZmJ/fv3Y/fu3SgvL0dQUBAmTZoEGxsbA3RJVVFxzl9hYSFWrFiBX375Bd27d4eNjQ1u376NpKQkfP/997C2tsbgwYMxb948tGvXjl9kiP4BAxGJKv7QfvLJJ9iyZQv27dsHlUqFwYMHY9OmTRgyZIihW6TndPz4cfTs2bPS8v/973945513YG5ujg8//BDjx483QHdUFRXBZtCgQcjPz4eFhQW0Wi0sLS3Rvn179O3bF6+88gqMjIzEuaMYhoj+GQMRVXLu3DkEBASIJ1C7u7tj7969hm6LntOZM2cQHByM3r17Y9y4cejRo4e4TqvVYsKECXj55ZcRFhZmwC7paSqCze+//44hQ4bgwIEDcHR0xOXLl7Fu3TqkpKTA3Nwcfn5+GDFiBFq3bm3olonqDR5Qpkrc3Nzwxx9/YPPmzfj888+xdetWAOD9rOo5W1tbDB8+HFeuXEFERAQWLlyIa9euAXg4udvFixfRrVs3ANzXdVXFKE9aWho8PDzEiVLbtm2LJUuW4D//+Q9atWqFVatWITMz04CdEtU/HCEikpiMjAxs2bIFqampaNSoEWxtbaHVanH58mWcP3/e0O3RP0hMTMT/+3//D/n5+Vi1alWlk+AB4NChQxg4cKABuiOqvxiIiBqox+9xdfjwYbi6uqJ169Zo06YNDhw4gBMnTiAlJQXOzs6YOXMmOnbsyEuz67iysjLs2rUL0dHRMDY2xsiRIzFkyBA4OztXquW5Q0RVx0BE1ED93T2uXnrpJXzxxRdo2rSpeCI91T8lJSVYunSpeB5RYGAgBgwYAHt7e0O3RlQv8WsgUQP0tHtcOTk5oWnTpsjPz0deXp6hW6Vn1KRJE0RFRWHPnj0wNzfHihUrMG/ePPEeV0SkH44QETVgvMeVdBw7dgwXL17ElClTeKiM6BlwhIioAar4nuPg4ABTU1MAwNy5c/Huu++Kc9OoVCqcOHGCYaiB8PX1xZQpUwCAYYjoGTAQETVAFR+ILVu2xLfffosJEyZALpeLN/wsKCjAqlWr8K9//QvAw0NsRERSxnuZETUgvMcVEdGz4TlERA0E73FFRPTsGIiIGgje44qI6NnxkBlRA/DoPa6uXr36xHtc/fHHH7h8+TJGjBghPo9hiIjoIZ44QNQA8B5XRETPh4fMiBoI3uOKiOjZMRARNRC8xxUR0bNjICJqYHiPKyIi/TEQETVQf/75JxYsWIDMzEx07doVq1evhrm5uaHbIiKqkxiIiBo43uOKiOifMRARERGR5PGyeyIiIpI8BiIiIiKSPAYiIiIikjwGIiIiIpI8BiIiIiKSPAYiIiIikjwGIiIiIpI8BiIiIiKSPAYiIiIikrz/D1WsfiSMWdOgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate minority and majority classes\n",
    "news = df1[df1['sentiment']== 2]\n",
    "pro = df1[df1['sentiment']== 1]\n",
    "neutral = df1[df1['sentiment']== 0]\n",
    "anti = df1[df1['sentiment']== -1]\n",
    "\n",
    "labels = df1['sentiment'].unique()\n",
    "heights = [len(news),len(pro), len(neutral), len(anti)]\n",
    "plt.bar(labels,heights,color='green')\n",
    "plt.xticks(labels,['news(2)','pro(1)', 'neutral(0)', 'anti(-1)'], rotation = 60)\n",
    "plt.ylabel(\"no. of observations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove Stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.copy() #Let us make a copy of our dataframe to avoid modifying the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "#To get a list of english stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable</td>\n",
       "      <td>625221</td>\n",
       "      <td>PolySciMajor EPA chief think carbon dioxide main cause global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It's not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…</td>\n",
       "      <td>698562</td>\n",
       "      <td>RT @RawStory: Researchers say three years act climate change it’s late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD</td>\n",
       "      <td>573736</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 pivotal year war climate change https://t.co/44wOTxTLcD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight</td>\n",
       "      <td>466954</td>\n",
       "      <td>RT @SoyNovioDeTodas: 2016, racist, sexist, climate change denying bigot leading polls. #ElectionNight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0        1.0   \n",
       "1        1.0   \n",
       "2        2.0   \n",
       "3        1.0   \n",
       "4        1.0   \n",
       "\n",
       "                                                                                                                                        message  \\\n",
       "0  PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable   \n",
       "1                                                                                It's not like we lack evidence of anthropogenic global warming   \n",
       "2  RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…   \n",
       "3                                           #TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD   \n",
       "4                    RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight   \n",
       "\n",
       "   tweetid  \\\n",
       "0   625221   \n",
       "1   126103   \n",
       "2   698562   \n",
       "3   573736   \n",
       "4   466954   \n",
       "\n",
       "                                                                                                                    clean_message  \n",
       "0  PolySciMajor EPA chief think carbon dioxide main cause global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable  \n",
       "1                                                                                 like lack evidence anthropogenic global warming  \n",
       "2             RT @RawStory: Researchers say three years act climate change it’s late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…  \n",
       "3                                             #TodayinMaker# WIRED : 2016 pivotal year war climate change https://t.co/44wOTxTLcD  \n",
       "4                           RT @SoyNovioDeTodas: 2016, racist, sexist, climate change denying bigot leading polls. #ElectionNight  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " clean_texts = []\n",
    "\n",
    "for text in df_train['message']:\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    clean_text = ' '.join(filtered_words)\n",
    "    clean_texts.append(clean_text)\n",
    "\n",
    "# clean_texts\n",
    "df_train['clean_message'] = clean_texts\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**\n",
    "Should we drop the original message column at this point? Or would it be useful for future reference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove Urls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove urls and replace with 'url'\n",
    " \n",
    "pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "\n",
    "subs_url = r'url'\n",
    "\n",
    "df_train['clean_message'] = df_train['clean_message'].replace(to_replace = pattern_url, value = subs_url, regex = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RawStory: Researchers say three years act climate change it’s late url url…'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_message'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove Punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "#Convert message to lower case\n",
    "df_train['clean_message'] = df_train['clean_message'].str.lower()\n",
    "\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt paigetweedy offense… like… believe… global warming………'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(message):\n",
    "    return ''.join([l for l in message if l not in string.punctuation])\n",
    "\n",
    "\n",
    "df_train['clean_message'] = df_train['clean_message'].apply(remove_punctuation)\n",
    "df_train['clean_message'].iloc[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt rawstory researchers say three years act climate change it’s late url url…'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_message'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite removing puntuations, we still observe some curly quotation marks and repeated punctuations.\n",
    "\n",
    "Let's deal with these using regular expression(regex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt rawstory researchers say three years act climate change its late url url'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s\"“”]', '', text)  # Remove non-alphanumeric characters and curly quotation marks\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespaces\n",
    "    text = re.sub(r'([!?.])\\1+', r'\\1', text)  # Remove repeated punctuation marks\n",
    "    return text.strip()\n",
    "\n",
    "# Apply the clean_text function to the 'message' column\n",
    "df_train['clean_message'] = df_train['clean_message'].apply(clean_text)\n",
    "df_train['clean_message'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt paigetweedy offense like believe global warming'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_message'].iloc[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our data has been delivered of every noise......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26365, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop([\"message\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researchers say three years act climate change its late url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweetid  \\\n",
       "0        1.0   625221   \n",
       "1        1.0   126103   \n",
       "2        2.0   698562   \n",
       "3        1.0   573736   \n",
       "4        1.0   466954   \n",
       "\n",
       "                                                                                          clean_message  \n",
       "0  polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable  \n",
       "1                                                       like lack evidence anthropogenic global warming  \n",
       "2                           rt rawstory researchers say three years act climate change its late url url  \n",
       "3                                           todayinmaker wired 2016 pivotal year war climate change url  \n",
       "4        rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "      <td>[polyscimajor, epa, chief, think, carbon, dioxide, main, cause, global, warming, and, wait, what, url, via, mashable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, warming]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researchers say three years act climate change its late url url</td>\n",
       "      <td>[rt, rawstory, researchers, say, three, years, act, climate, change, its, late, url, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war, climate, change, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight</td>\n",
       "      <td>[rt, soynoviodetodas, 2016, racist, sexist, climate, change, denying, bigot, leading, polls, electionnight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>NaN</td>\n",
       "      <td>895714</td>\n",
       "      <td>rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url</td>\n",
       "      <td>[rt, brittanybohrer, brb, writing, poem, climate, change, climatechange, science, poetry, fakenews, alternativefacts, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>875167</td>\n",
       "      <td>2016 year climate change came home hottest year record karl mathiesen travelled tasmania url</td>\n",
       "      <td>[2016, year, climate, change, came, home, hottest, year, record, karl, mathiesen, travelled, tasmania, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78329</td>\n",
       "      <td>rt loopvanuatu pacific countries positive fiji leading global climate change conference november url</td>\n",
       "      <td>[rt, loopvanuatu, pacific, countries, positive, fiji, leading, global, climate, change, conference, november, url]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>NaN</td>\n",
       "      <td>867455</td>\n",
       "      <td>rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585</td>\n",
       "      <td>[rt, xanria00018, youre, hot, must, cause, global, warming, aldublaboroflove, jophie30, asn585]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>470892</td>\n",
       "      <td>rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h</td>\n",
       "      <td>[rt, chloebalaoing, climate, change, global, issue, thats, getting, worse, eating, plant, based, least, amount, effort, h]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26365 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  tweetid  \\\n",
       "0            1.0   625221   \n",
       "1            1.0   126103   \n",
       "2            2.0   698562   \n",
       "3            1.0   573736   \n",
       "4            1.0   466954   \n",
       "...          ...      ...   \n",
       "10541        NaN   895714   \n",
       "10542        NaN   875167   \n",
       "10543        NaN    78329   \n",
       "10544        NaN   867455   \n",
       "10545        NaN   470892   \n",
       "\n",
       "                                                                                                      clean_message  \\\n",
       "0              polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable   \n",
       "1                                                                   like lack evidence anthropogenic global warming   \n",
       "2                                       rt rawstory researchers say three years act climate change its late url url   \n",
       "3                                                       todayinmaker wired 2016 pivotal year war climate change url   \n",
       "4                    rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight   \n",
       "...                                                                                                             ...   \n",
       "10541  rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url   \n",
       "10542                  2016 year climate change came home hottest year record karl mathiesen travelled tasmania url   \n",
       "10543          rt loopvanuatu pacific countries positive fiji leading global climate change conference november url   \n",
       "10544                           rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585   \n",
       "10545     rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h   \n",
       "\n",
       "                                                                                                                         tokenize  \n",
       "0           [polyscimajor, epa, chief, think, carbon, dioxide, main, cause, global, warming, and, wait, what, url, via, mashable]  \n",
       "1                                                                          [like, lack, evidence, anthropogenic, global, warming]  \n",
       "2                                       [rt, rawstory, researchers, say, three, years, act, climate, change, its, late, url, url]  \n",
       "3                                                           [todayinmaker, wired, 2016, pivotal, year, war, climate, change, url]  \n",
       "4                     [rt, soynoviodetodas, 2016, racist, sexist, climate, change, denying, bigot, leading, polls, electionnight]  \n",
       "...                                                                                                                           ...  \n",
       "10541  [rt, brittanybohrer, brb, writing, poem, climate, change, climatechange, science, poetry, fakenews, alternativefacts, url]  \n",
       "10542                 [2016, year, climate, change, came, home, hottest, year, record, karl, mathiesen, travelled, tasmania, url]  \n",
       "10543          [rt, loopvanuatu, pacific, countries, positive, fiji, leading, global, climate, change, conference, november, url]  \n",
       "10544                             [rt, xanria00018, youre, hot, must, cause, global, warming, aldublaboroflove, jophie30, asn585]  \n",
       "10545  [rt, chloebalaoing, climate, change, global, issue, thats, getting, worse, eating, plant, based, least, amount, effort, h]  \n",
       "\n",
       "[26365 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser = TreebankWordTokenizer()\n",
    "df_train['tokenize'] = df_train['clean_message'].apply(tokeniser.tokenize)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemma(words, lemmatizer):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "\n",
    "# df_train['lemmatized'] = df_train['tokenize'].apply(lambda x: [lemmatizer.lemmatize(i) for i in x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lemmatized'] = df_train['tokenize'].apply(lemma, args=(lemmatizer, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>clean_message</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "      <td>[polyscimajor, epa, chief, think, carbon, dioxide, main, cause, global, warming, and, wait, what, url, via, mashable]</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, warming]</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researchers say three years act climate change its late url url</td>\n",
       "      <td>[rt, rawstory, researchers, say, three, years, act, climate, change, its, late, url, url]</td>\n",
       "      <td>rt rawstory researcher say three year act climate change it late url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war, climate, change, url]</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight</td>\n",
       "      <td>[rt, soynoviodetodas, 2016, racist, sexist, climate, change, denying, bigot, leading, polls, electionnight]</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>NaN</td>\n",
       "      <td>895714</td>\n",
       "      <td>rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url</td>\n",
       "      <td>[rt, brittanybohrer, brb, writing, poem, climate, change, climatechange, science, poetry, fakenews, alternativefacts, url]</td>\n",
       "      <td>rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>875167</td>\n",
       "      <td>2016 year climate change came home hottest year record karl mathiesen travelled tasmania url</td>\n",
       "      <td>[2016, year, climate, change, came, home, hottest, year, record, karl, mathiesen, travelled, tasmania, url]</td>\n",
       "      <td>2016 year climate change came home hottest year record karl mathiesen travelled tasmania url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78329</td>\n",
       "      <td>rt loopvanuatu pacific countries positive fiji leading global climate change conference november url</td>\n",
       "      <td>[rt, loopvanuatu, pacific, countries, positive, fiji, leading, global, climate, change, conference, november, url]</td>\n",
       "      <td>rt loopvanuatu pacific country positive fiji leading global climate change conference november url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>NaN</td>\n",
       "      <td>867455</td>\n",
       "      <td>rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585</td>\n",
       "      <td>[rt, xanria00018, youre, hot, must, cause, global, warming, aldublaboroflove, jophie30, asn585]</td>\n",
       "      <td>rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>470892</td>\n",
       "      <td>rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h</td>\n",
       "      <td>[rt, chloebalaoing, climate, change, global, issue, thats, getting, worse, eating, plant, based, least, amount, effort, h]</td>\n",
       "      <td>rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26365 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  tweetid  \\\n",
       "0            1.0   625221   \n",
       "1            1.0   126103   \n",
       "2            2.0   698562   \n",
       "3            1.0   573736   \n",
       "4            1.0   466954   \n",
       "...          ...      ...   \n",
       "10541        NaN   895714   \n",
       "10542        NaN   875167   \n",
       "10543        NaN    78329   \n",
       "10544        NaN   867455   \n",
       "10545        NaN   470892   \n",
       "\n",
       "                                                                                                      clean_message  \\\n",
       "0              polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable   \n",
       "1                                                                   like lack evidence anthropogenic global warming   \n",
       "2                                       rt rawstory researchers say three years act climate change its late url url   \n",
       "3                                                       todayinmaker wired 2016 pivotal year war climate change url   \n",
       "4                    rt soynoviodetodas 2016 racist sexist climate change denying bigot leading polls electionnight   \n",
       "...                                                                                                             ...   \n",
       "10541  rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url   \n",
       "10542                  2016 year climate change came home hottest year record karl mathiesen travelled tasmania url   \n",
       "10543          rt loopvanuatu pacific countries positive fiji leading global climate change conference november url   \n",
       "10544                           rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585   \n",
       "10545     rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h   \n",
       "\n",
       "                                                                                                                         tokenize  \\\n",
       "0           [polyscimajor, epa, chief, think, carbon, dioxide, main, cause, global, warming, and, wait, what, url, via, mashable]   \n",
       "1                                                                          [like, lack, evidence, anthropogenic, global, warming]   \n",
       "2                                       [rt, rawstory, researchers, say, three, years, act, climate, change, its, late, url, url]   \n",
       "3                                                           [todayinmaker, wired, 2016, pivotal, year, war, climate, change, url]   \n",
       "4                     [rt, soynoviodetodas, 2016, racist, sexist, climate, change, denying, bigot, leading, polls, electionnight]   \n",
       "...                                                                                                                           ...   \n",
       "10541  [rt, brittanybohrer, brb, writing, poem, climate, change, climatechange, science, poetry, fakenews, alternativefacts, url]   \n",
       "10542                 [2016, year, climate, change, came, home, hottest, year, record, karl, mathiesen, travelled, tasmania, url]   \n",
       "10543          [rt, loopvanuatu, pacific, countries, positive, fiji, leading, global, climate, change, conference, november, url]   \n",
       "10544                             [rt, xanria00018, youre, hot, must, cause, global, warming, aldublaboroflove, jophie30, asn585]   \n",
       "10545  [rt, chloebalaoing, climate, change, global, issue, thats, getting, worse, eating, plant, based, least, amount, effort, h]   \n",
       "\n",
       "                                                                                                         lemmatized  \n",
       "0              polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable  \n",
       "1                                                                   like lack evidence anthropogenic global warming  \n",
       "2                                          rt rawstory researcher say three year act climate change it late url url  \n",
       "3                                                       todayinmaker wired 2016 pivotal year war climate change url  \n",
       "4                     rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight  \n",
       "...                                                                                                             ...  \n",
       "10541  rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url  \n",
       "10542                  2016 year climate change came home hottest year record karl mathiesen travelled tasmania url  \n",
       "10543            rt loopvanuatu pacific country positive fiji leading global climate change conference november url  \n",
       "10544                           rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585  \n",
       "10545     rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h  \n",
       "\n",
       "[26365 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###drop unwanted columns\n",
    "df_train = df_train.drop(['tokenize'], axis =1)\n",
    "df_train = df_train.drop(['clean_message'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researcher say three year act climate change it late url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>NaN</td>\n",
       "      <td>895714</td>\n",
       "      <td>rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>875167</td>\n",
       "      <td>2016 year climate change came home hottest year record karl mathiesen travelled tasmania url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78329</td>\n",
       "      <td>rt loopvanuatu pacific country positive fiji leading global climate change conference november url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>NaN</td>\n",
       "      <td>867455</td>\n",
       "      <td>rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>470892</td>\n",
       "      <td>rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  tweetid  \\\n",
       "0            1.0   625221   \n",
       "1            1.0   126103   \n",
       "2            2.0   698562   \n",
       "3            1.0   573736   \n",
       "4            1.0   466954   \n",
       "...          ...      ...   \n",
       "10541        NaN   895714   \n",
       "10542        NaN   875167   \n",
       "10543        NaN    78329   \n",
       "10544        NaN   867455   \n",
       "10545        NaN   470892   \n",
       "\n",
       "                                                                                                         lemmatized  \n",
       "0              polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable  \n",
       "1                                                                   like lack evidence anthropogenic global warming  \n",
       "2                                          rt rawstory researcher say three year act climate change it late url url  \n",
       "3                                                       todayinmaker wired 2016 pivotal year war climate change url  \n",
       "4                     rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight  \n",
       "...                                                                                                             ...  \n",
       "10541  rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url  \n",
       "10542                  2016 year climate change came home hottest year record karl mathiesen travelled tasmania url  \n",
       "10543            rt loopvanuatu pacific country positive fiji leading global climate change conference november url  \n",
       "10544                           rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585  \n",
       "10545     rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h  \n",
       "\n",
       "[26365 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(df_train['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researcher say three year act climate change it late url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  tweetid  \\\n",
       "0        1.0   625221   \n",
       "1        1.0   126103   \n",
       "2        2.0   698562   \n",
       "3        1.0   573736   \n",
       "4        1.0   466954   \n",
       "\n",
       "                                                                                             lemmatized  \n",
       "0  polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable  \n",
       "1                                                       like lack evidence anthropogenic global warming  \n",
       "2                              rt rawstory researcher say three year act climate change it late url url  \n",
       "3                                           todayinmaker wired 2016 pivotal year war climate change url  \n",
       "4         rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "betterVect = CountVectorizer(stop_words='english', \n",
    "                             min_df=2, \n",
    "                             max_df=0.5, \n",
    "                             ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=betterVect.fit_transform(df_train['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_df=0.5, min_df=2, stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.5, min_df=2, stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_df=0.5, min_df=2, stop_words='english')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betterVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>625221</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>126103</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>698562</td>\n",
       "      <td>rt rawstory researcher say three year act climate change it late url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>573736</td>\n",
       "      <td>todayinmaker wired 2016 pivotal year war climate change url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>466954</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>NaN</td>\n",
       "      <td>895714</td>\n",
       "      <td>rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>NaN</td>\n",
       "      <td>875167</td>\n",
       "      <td>2016 year climate change came home hottest year record karl mathiesen travelled tasmania url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>NaN</td>\n",
       "      <td>78329</td>\n",
       "      <td>rt loopvanuatu pacific country positive fiji leading global climate change conference november url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>NaN</td>\n",
       "      <td>867455</td>\n",
       "      <td>rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>NaN</td>\n",
       "      <td>470892</td>\n",
       "      <td>rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26365 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  tweetid  \\\n",
       "0            1.0   625221   \n",
       "1            1.0   126103   \n",
       "2            2.0   698562   \n",
       "3            1.0   573736   \n",
       "4            1.0   466954   \n",
       "...          ...      ...   \n",
       "10541        NaN   895714   \n",
       "10542        NaN   875167   \n",
       "10543        NaN    78329   \n",
       "10544        NaN   867455   \n",
       "10545        NaN   470892   \n",
       "\n",
       "                                                                                                         lemmatized  \n",
       "0              polyscimajor epa chief think carbon dioxide main cause global warming and wait what url via mashable  \n",
       "1                                                                   like lack evidence anthropogenic global warming  \n",
       "2                                          rt rawstory researcher say three year act climate change it late url url  \n",
       "3                                                       todayinmaker wired 2016 pivotal year war climate change url  \n",
       "4                     rt soynoviodetodas 2016 racist sexist climate change denying bigot leading poll electionnight  \n",
       "...                                                                                                             ...  \n",
       "10541  rt brittanybohrer brb writing poem climate change climatechange science poetry fakenews alternativefacts url  \n",
       "10542                  2016 year climate change came home hottest year record karl mathiesen travelled tasmania url  \n",
       "10543            rt loopvanuatu pacific country positive fiji leading global climate change conference november url  \n",
       "10544                           rt xanria00018 youre hot must cause global warming aldublaboroflove jophie30 asn585  \n",
       "10545     rt chloebalaoing climate change global issue thats getting worse eating plant based least amount effort h  \n",
       "\n",
       "[26365 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3693)\t1\n",
      "  (0, 1964)\t1\n",
      "  (0, 10230)\t1\n",
      "  (0, 1724)\t1\n",
      "  (0, 3097)\t1\n",
      "  (0, 6353)\t1\n",
      "  (0, 1785)\t1\n",
      "  (0, 4516)\t1\n",
      "  (0, 10991)\t1\n",
      "  (0, 10960)\t1\n",
      "  (0, 10780)\t1\n",
      "  (0, 6469)\t1\n",
      "  (1, 4516)\t1\n",
      "  (1, 10991)\t1\n",
      "  (1, 6162)\t1\n",
      "  (1, 5965)\t1\n",
      "  (1, 3784)\t1\n",
      "  (1, 794)\t1\n",
      "  (2, 10780)\t2\n",
      "  (2, 8344)\t1\n",
      "  (2, 8621)\t1\n",
      "  (2, 8978)\t1\n",
      "  (2, 11348)\t1\n",
      "  (2, 380)\t1\n",
      "  (2, 6004)\t1\n",
      "  :\t:\n",
      "  (26362, 6045)\t1\n",
      "  (26362, 2542)\t1\n",
      "  (26362, 7153)\t1\n",
      "  (26362, 2356)\t1\n",
      "  (26362, 7451)\t1\n",
      "  (26362, 7900)\t1\n",
      "  (26362, 4085)\t1\n",
      "  (26363, 1785)\t1\n",
      "  (26363, 4516)\t1\n",
      "  (26363, 10991)\t1\n",
      "  (26363, 5065)\t1\n",
      "  (26363, 11379)\t1\n",
      "  (26363, 584)\t1\n",
      "  (26363, 11313)\t1\n",
      "  (26363, 5726)\t1\n",
      "  (26363, 947)\t1\n",
      "  (26364, 4516)\t1\n",
      "  (26364, 5545)\t1\n",
      "  (26364, 10134)\t1\n",
      "  (26364, 7760)\t1\n",
      "  (26364, 3508)\t1\n",
      "  (26364, 3445)\t1\n",
      "  (26364, 11258)\t1\n",
      "  (26364, 4480)\t1\n",
      "  (26364, 1154)\t1\n"
     ]
    }
   ],
   "source": [
    "print(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  2., ..., nan, nan, nan])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment\n",
       "0            1.0\n",
       "1            1.0\n",
       "2            2.0\n",
       "3            1.0\n",
       "4            1.0\n",
       "...          ...\n",
       "15814        1.0\n",
       "15815        2.0\n",
       "15816        0.0\n",
       "15817       -1.0\n",
       "15818        0.0\n",
       "\n",
       "[15819 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_train[:len(df1)][[\"sentiment\"]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3693)\t1\n",
      "  (0, 1964)\t1\n",
      "  (0, 10230)\t1\n",
      "  (0, 1724)\t1\n",
      "  (0, 3097)\t1\n",
      "  (0, 6353)\t1\n",
      "  (0, 1785)\t1\n",
      "  (0, 4516)\t1\n",
      "  (0, 10991)\t1\n",
      "  (0, 10960)\t1\n",
      "  (0, 10780)\t1\n",
      "  (0, 6469)\t1\n",
      "  (1, 4516)\t1\n",
      "  (1, 10991)\t1\n",
      "  (1, 6162)\t1\n",
      "  (1, 5965)\t1\n",
      "  (1, 3784)\t1\n",
      "  (1, 794)\t1\n",
      "  (2, 10780)\t2\n",
      "  (2, 8344)\t1\n",
      "  (2, 8621)\t1\n",
      "  (2, 8978)\t1\n",
      "  (2, 11348)\t1\n",
      "  (2, 380)\t1\n",
      "  (2, 6004)\t1\n",
      "  :\t:\n",
      "  (15815, 10780)\t1\n",
      "  (15815, 1503)\t1\n",
      "  (15815, 11013)\t1\n",
      "  (15815, 8524)\t1\n",
      "  (15815, 89)\t1\n",
      "  (15816, 10780)\t1\n",
      "  (15816, 1236)\t1\n",
      "  (15816, 10501)\t1\n",
      "  (15816, 8736)\t1\n",
      "  (15816, 7640)\t1\n",
      "  (15816, 5698)\t1\n",
      "  (15816, 544)\t1\n",
      "  (15816, 404)\t1\n",
      "  (15816, 7208)\t1\n",
      "  (15817, 4938)\t1\n",
      "  (15817, 1878)\t1\n",
      "  (15817, 5004)\t1\n",
      "  (15817, 6133)\t1\n",
      "  (15817, 2581)\t1\n",
      "  (15817, 10295)\t1\n",
      "  (15817, 514)\t1\n",
      "  (15817, 8947)\t1\n",
      "  (15817, 1648)\t1\n",
      "  (15818, 10780)\t1\n",
      "  (15818, 3705)\t1\n"
     ]
    }
   ],
   "source": [
    "X_train=df_new[:len(df1)]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  2., ...,  0., -1.,  0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[\"sentiment\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TEST=df_new[len(df1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 11458)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_TEST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our parameters are y,X_train,X_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train,y[\"sentiment\"].values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the tweet vectors\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_TEST_scaled= scaler.transform(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the SVC is: 0.7196586599241467\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.50      0.54       278\n",
      "         0.0       0.45      0.53      0.49       425\n",
      "         1.0       0.80      0.78      0.79      1755\n",
      "         2.0       0.76      0.76      0.76       706\n",
      "\n",
      "    accuracy                           0.72      3164\n",
      "   macro avg       0.65      0.64      0.65      3164\n",
      "weighted avg       0.72      0.72      0.72      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"The accuracy score of the SVC is:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of the SVC is: 0.5989254108723135\n",
      "\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.38      0.49      0.43       278\n",
      "         0.0       0.33      0.49      0.40       425\n",
      "         1.0       0.75      0.63      0.69      1755\n",
      "         2.0       0.63      0.63      0.63       706\n",
      "\n",
      "    accuracy                           0.60      3164\n",
      "   macro avg       0.52      0.56      0.54      3164\n",
      "weighted avg       0.64      0.60      0.61      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "print(\"The accuracy score of the SVC is:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\\nClassification Report:\\n\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was noticed that training with unscaled data led to higher training accuracy but lower test accuracy. Inshort scale ur data. Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Using SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Fit the GridSearchCV on the training data\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Print the best parameters and best score\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    770\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:444\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    443\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:722\u001b[0m, in \u001b[0;36mPipeline.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     score_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 722\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mscore(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:649\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:820\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    818\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    434\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:481\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[0;32m    479\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# C is not useful here\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLIBSVM_IMPL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Create a pipeline with CountVectorizer and SVC\n",
    "vectorizer = CountVectorizer()\n",
    "pipeline = Pipeline([\n",
    "    ('svc', SVC())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    0: Neutral       0.55      0.46      0.50       278\n",
      " 1: ProClimate       0.39      0.49      0.44       425\n",
      "       2: News       0.76      0.72      0.74      1755\n",
      "-1:AntiClimate       0.67      0.70      0.69       706\n",
      "\n",
      "      accuracy                           0.66      3164\n",
      "     macro avg       0.59      0.59      0.59      3164\n",
      "  weighted avg       0.67      0.66      0.67      3164\n",
      "\n",
      "The accuracy score of the SVC is: 0.6630847029077117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, pred_lr, target_names=['0: Neutral', '1: ProClimate','2: News','-1:AntiClimate']))\n",
    "\n",
    "print(\"The accuracy score of the SVC is:\", accuracy_score(y_test, pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = nb_classifier.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6419089759797725\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier()\n",
    "mlp_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_predictions = mlp_classifier.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy: 0.690897597977244\n"
     ]
    }
   ],
   "source": [
    "mlp_accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "print(\"MLP Accuracy:\", mlp_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1083/1582 [===================>..........] - ETA: 3:30:48 - loss: 0.2792 - accuracy: 0.5347"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Assuming you have already prepared your training and testing data: X_trainrnn, X_testrnn, y_train, y_test\n",
    "\n",
    "# Convert sparse input data to dense arrays\n",
    "X_trainrnn = X_train_scaled.toarray()\n",
    "X_testrnn = X_test_scaled.toarray()\n",
    "\n",
    "# Determine the number of unique tokens in your input data\n",
    "num_tokens = int(np.max([np.max(X_trainrnn[i, :]) for i in range(X_trainrnn.shape[0])]) + 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_tokens, output_dim=32))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_trainrnn, y_train, batch_size=8, epochs=10, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "_, accuracy = model.evaluate(X_testrnn, y_test)\n",
    "print(\"RNN Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfomers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming X_train_scaled, X_test_scaled, y_train, and y_test are available\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert input data to list of strings\n",
    "X_train_texts = [str(seq) for seq in X_train_scaled]\n",
    "X_test_texts = [str(seq) for seq in X_test_scaled]\n",
    "\n",
    "# Tokenize and pad the input sequences\n",
    "input_ids = tokenizer.batch_encode_plus(X_train_texts, padding='longest', truncation=True, return_tensors='tf')['input_ids']\n",
    "input_ids_test = tokenizer.batch_encode_plus(X_test_texts, padding='longest', truncation=True, return_tensors='tf')['input_ids']\n",
    "\n",
    "# Build the model architecture\n",
    "input_layer = Input(shape=(input_ids.shape[1],), dtype=tf.int32)\n",
    "bert_output = bert_model(input_layer)[0][:, 0, :]\n",
    "output_layer = Dense(1, activation='sigmoid')(bert_output)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(input_ids, y_train, batch_size=8, epochs=3, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(input_ids_test)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Transformers Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7035398230088495\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define your random forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {'n_estimators': [100, 200, 300, 400, 500]}\n",
    "\n",
    "# Perform grid search using cross-validation\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X, y)  # X is your feature matrix, y is your target variable\n",
    "\n",
    "# Get the best parameter value\n",
    "best_n_estimators = grid_search.best_params_['n_estimators']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 5],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 5],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 5],\n",
       "                         'n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 5],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Score: 0.705807981035164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=5, n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=5, n_estimators=200)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Train the classifier with the best parameters\n",
    "best_rf_classifier = RandomForestClassifier(**best_params)\n",
    "best_rf_classifier.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7221871049304678\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = best_rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainint=[int(i) for i in y_train]\n",
    "y_testint=[int(i) for i in y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map the labels to [0, 1, 2, 3] instead of 0,-1,2,\n",
    "\n",
    "\n",
    "\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_train = {label: idx for idx, label in enumerate(np.unique(y_trainint))}\n",
    "labels_train = np.array([label_mapping_train[label] for label in y_trainint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_test = {label: idx for idx, label in enumerate(np.unique(y_testint))}\n",
    "labels_test = np.array([label_mapping_test[label] for label in y_testint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7104930467762326\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "# Initialize XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier\n",
    "xgb_classifier.fit(X_train_scaled, labels_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test = xgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "#Now we convert changed prediction labels back\n",
    "\n",
    "# Define inverse mapping dictionaries\n",
    "inv_label_mapping_train = {idx: label for label, idx in label_mapping_train.items()}\n",
    "inv_label_mapping_test = {idx: label for label, idx in label_mapping_test.items()}\n",
    "y_pred_original_test = np.array([inv_label_mapping_test[pred] for pred in y_pred_test])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_original_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier using Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n540 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [-1.  0.  1.  2.]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform grid search to find the best parameters\u001b[39;00m\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(xgb_classifier, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Get the best parameters and score\u001b[39;00m\n\u001b[0;32m     18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    849\u001b[0m     )\n\u001b[1;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 540 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n540 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n    return func(**kwargs)\n  File \"C:\\Users\\DELL\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1440, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [-1.  0.  1.  2.]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for grid search \n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "grid_search = GridSearchCV(xgb_classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Train the classifier with the best parameters\n",
    "best_xgb_classifier = xgb.XGBClassifier(**best_params)\n",
    "best_xgb_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_test = best_xgb_classifier.predict(X_test_scaled)\n",
    "\n",
    "#Now we convert changed prediction labels back\n",
    "\n",
    "# Define inverse mapping dictionaries\n",
    "inv_label_mapping_train = {idx: label for label, idx in label_mapping_train.items()}\n",
    "inv_label_mapping_test = {idx: label for label, idx in label_mapping_test.items()}\n",
    "y_pred_original_test = np.array([inv_label_mapping_test[pred] for pred in y_pred_test])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_original_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGBoost Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing result for submission\n",
    "# result=lr.predict(X_TEST_scaled)\n",
    "# res = svc.predict(X_TEST_scaled)\n",
    "res = best_rf_classifier.predict(X_TEST_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=[int(i) for i in result]\n",
    "res=[int(i) for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " -1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10546, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DAF=pd.DataFrame(result,columns=[\"sentiment\"])\n",
    "# DAF.head()\n",
    "DAF=pd.DataFrame(res,columns=[\"sentiment\"])\n",
    "DAF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [3164, 10546]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [3164, 10546]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, res)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid  sentiment\n",
       "0       169760          2\n",
       "1        35326          1\n",
       "2       224985          1\n",
       "3       476263          1\n",
       "4       872928          0\n",
       "...        ...        ...\n",
       "10541   895714          1\n",
       "10542   875167          1\n",
       "10543    78329          1\n",
       "10544   867455          0\n",
       "10545   470892          1\n",
       "\n",
       "[10546 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=pd.DataFrame({\"tweetid\":test_df[\"tweetid\"]})\n",
    "submission=output.join(DAF)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
