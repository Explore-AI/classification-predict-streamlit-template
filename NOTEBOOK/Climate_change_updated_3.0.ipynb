{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc6wG-x8VxWI"
   },
   "source": [
    "<a id='Top'></a>\n",
    "# CLASSIFICATION CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYCbx3PSVxWK"
   },
   "source": [
    "# Outline\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Import necessary libraries](#Import)\n",
    "- [Loading Datasets](#Load)\n",
    "- [Data Preprocessing](#section-four)\n",
    "- EDA\n",
    "  * Analysis of the data\n",
    "  \n",
    "- [Classification Models](#)  \n",
    "- [Feature Egineering](#feature_engineering)\n",
    " * [TF-IDF](#tfidf)\n",
    " * [WORD2VEC](word2vec) \n",
    "- [Pipelines](#Pipelines)\n",
    "  * [Building Classification Pipelines](#classifiers)\n",
    "  * [Using Word2Vec](#pipe_word2vec)\n",
    "- [Modelling and Evaluation](#model_eval)\n",
    "  * [Modelling - Raw tweets](#raw_tweets)\n",
    "  * [Modelling - Cleaned tweets](#clean_tweets)\n",
    "  * [Model perfomance (raw tweets vs cleaned tweets)](#rvc)\n",
    "  * [Model perfomance (tfidf vs word2vec)](tfidfvsword2vec)\n",
    "- [Ensemble Method](#ensemble)\n",
    "- [Choosing the champion model](#cham_model)\n",
    "- [Hyperparameter tunning](#hy_tunning)\n",
    "- [Predictions](#predictions)\n",
    "- [Submission](#submission)  \n",
    "- [Conclusion](#conclusion)\n",
    "- [Appendix](#appendix)\n",
    "- [References](#references)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLmvjzUHVxWL"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKSm-P-cVxWL"
   },
   "source": [
    "Companies are constructed around lessening ones environment impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0TMPN2QVxWM"
   },
   "source": [
    "**Problen Statement**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lP2Ak42VxWN"
   },
   "source": [
    "Create a Natural Language Processing model to classify whether or not a person believes in climate change, based on their novel tweet data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXS6GOF4VxWO"
   },
   "source": [
    "<a id=\"comet\"></a>\n",
    "# Starting a Comet experiment\n",
    "<img src=\"https://www.comet.ml/images/logo_comet_light.png\" width=\"350\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "We will be using Comet as a form of version control throughout the development of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JywImZYjVxWP"
   },
   "outputs": [],
   "source": [
    "# install comet\n",
    "# !pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mlA4RuG5VxWT"
   },
   "outputs": [],
   "source": [
    "# importing Experiment from comet\n",
    "# from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dgFkJIugVxWX"
   },
   "outputs": [],
   "source": [
    "# # Linking our current workspace to comet by creating an experiment with our api key:\n",
    "# experiment = Experiment(\n",
    "#     api_key=\"YBjEZqF3vM9CQLf2Lx7GeSw0C\",\n",
    "#     project_name=\"general\",\n",
    "#     workspace=\"mpho-mokhokane\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mlmhv02W9x7C",
    "outputId": "49f96a3e-8875-48fa-9bfa-549dfb595419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Using cached contractions-0.0.25-py2.py3-none-any.whl (3.2 kB)\n",
      "Collecting textsearch\n",
      "  Using cached textsearch-0.0.17-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Using cached pyahocorasick-1.4.0.tar.gz (312 kB)\n",
      "Requirement already satisfied: Unidecode in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch->contractions) (1.1.1)\n",
      "Building wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py): started\n",
      "  Building wheel for pyahocorasick (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyahocorasick\n",
      "Failed to build pyahocorasick\n",
      "Installing collected packages: pyahocorasick, textsearch, contractions\n",
      "    Running setup.py install for pyahocorasick: started\n",
      "    Running setup.py install for pyahocorasick: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\users\\user\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-wheel-0qepss3i'\n",
      "       cwd: C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-zvx1j5ou\\pyahocorasick\\\n",
      "  Complete output (5 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_ext\n",
      "  building 'ahocorasick' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyahocorasick\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\users\\user\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-q9ttjqiy\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\users\\user\\anaconda3\\Include\\pyahocorasick'\n",
      "         cwd: C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-zvx1j5ou\\pyahocorasick\\\n",
      "    Complete output (5 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_ext\n",
      "    building 'ahocorasick' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'c:\\users\\user\\anaconda3\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\pip-install-zvx1j5ou\\\\pyahocorasick\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\User\\AppData\\Local\\Temp\\pip-record-q9ttjqiy\\install-record.txt' --single-version-externally-managed --compile --install-headers 'c:\\users\\user\\anaconda3\\Include\\pyahocorasick' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv699tZoVxWa"
   },
   "source": [
    "<a id='Import'></a>\n",
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sO9zIRsnVxWb",
    "outputId": "f77c716c-0b7e-4bb0-a9a5-24f6ccfff13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: parfit in c:\\users\\user\\anaconda3\\lib\\site-packages (0.220)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from parfit) (1.19.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from parfit) (0.14.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\user\\anaconda3\\lib\\site-packages (from parfit) (0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from parfit) (3.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from sklearn->parfit) (0.22.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->parfit) (2.4.6)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->parfit) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->parfit) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->parfit) (45.2.0.post20200210)\n",
      "Requirement already satisfied: scikit-plot in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (0.22.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (3.1.3)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (1.19.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.0->scikit-plot) (45.2.0.post20200210)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.14.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'contractions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6084f8000cc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcontractions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'contractions'"
     ]
    }
   ],
   "source": [
    "!pip install parfit\n",
    "!pip install scikit-plot\n",
    "\n",
    "# imports for data visualisation\n",
    "\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# imports for Natural Language  Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import contractions\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRFClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "from scikitplot.metrics import plot_roc, plot_confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_3ug5QbRQdd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3wBf9yqVxWf"
   },
   "source": [
    "<a id='Load'></a>\n",
    "# Load and view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4EmHepW1VxWg"
   },
   "outputs": [],
   "source": [
    "# Importing the train & test data sets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaXQWG2xVxWl"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0US091BsjPe"
   },
   "source": [
    "Identifying Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwILDyvnSd4V"
   },
   "outputs": [],
   "source": [
    "train_data = train.copy()\n",
    "test_data = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gi8CvqYlVxWm",
    "outputId": "1e5d7baa-a9cb-48fb-f621-fa26013a1dba"
   },
   "outputs": [],
   "source": [
    "#Cheching if there are missing values in the Train dataset\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yM00FFVVxXM",
    "outputId": "68f2e81b-e9f5-4268-eaa9-b3f593dffd09"
   },
   "outputs": [],
   "source": [
    "#Cheching if there are missing values in the Test dataset\n",
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHaUuffLVxXR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e-cdv2vxYDU"
   },
   "source": [
    "Removing Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "23NSGRl5VxXU",
    "outputId": "61b6b154-720c-492a-ff7a-2eaddc3cb026"
   },
   "outputs": [],
   "source": [
    "def mentions(x):\n",
    "    x = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", x)\n",
    "    return x \n",
    "\n",
    "train['message'] = train['message'].apply(mentions)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jELrgFWxiha"
   },
   "source": [
    "Expand Contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "C7LXowvAxsDq",
    "outputId": "b2cf75a2-3c20-4cfa-d566-651f8c58876e"
   },
   "outputs": [],
   "source": [
    "train['message'] = train['message'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqX-qoppGinx"
   },
   "source": [
    "Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHEZwR0eGm7B"
   },
   "outputs": [],
   "source": [
    "train['message'] = train['message'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aStx7k71xteX"
   },
   "source": [
    "Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mouIzWBox57R"
   },
   "outputs": [],
   "source": [
    "def remove_punc(x):\n",
    "  x = re.sub(r\"([^A-Za-z0-9]+)\",\" \",x)\n",
    "  return x\n",
    "\n",
    "train['message'] = train['message'].map(lambda x: remove_punc(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aEWBGgcx6U2"
   },
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "DmUlQIgbx9Ck",
    "outputId": "bf473939-398f-418c-f527-b6988919de51"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "train['message'] = train['message'].apply(word_tokenize)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95GYlV-xx_Ld"
   },
   "source": [
    "Removing Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "id": "j_42GnZkyKTx",
    "outputId": "58148762-da51-4609-aac6-a3f6b0215797"
   },
   "outputs": [],
   "source": [
    "retweet = 'RT'\n",
    "train['message'] = train['message'].apply(lambda x: [word for word in x if word not in retweet])\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu74caNEyUdF"
   },
   "source": [
    "Conversion to Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ET7jZkXs-GY8",
    "outputId": "0ff7f35b-6cb9-4b1a-8561-30935e333949"
   },
   "outputs": [],
   "source": [
    "train['message'] = train['message'].apply(lambda x: [word.lower() for word in x])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qKaj-1U-MeY"
   },
   "source": [
    "Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "xNIXDzIf-QA-",
    "outputId": "24762b6d-7f70-479b-a450-02d257599b5e"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "UUd_vplm-U91",
    "outputId": "17321c40-3a3d-4f7c-bfd5-4682fb92a955"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "train['message'] = train['message'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peHsnPqZ-Z-Z"
   },
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "MbWUztQR-dV7",
    "outputId": "e2edffe0-7447-4278-d348-8145741ceb62"
   },
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "train['pos_tags'] = train['message'].apply(nltk.tag.pos_tag)\n",
    "train['wordnet_pos'] = train['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "\n",
    "train['message'] = train['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7idoQ_Dw-oZy"
   },
   "source": [
    "Most Frequent Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sCYUpb2-vsZ",
    "outputId": "94ac9e61-9cb8-473c-9cb4-68347b08830b"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for message in train['message'].values:\n",
    "    for word in message:\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eceDA71t-z6b"
   },
   "source": [
    "Separate Datframes of Tweets for each Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfcmDMTV--kM",
    "outputId": "e41269f4-8532-49e6-8ffd-a2f9a1ca5167"
   },
   "outputs": [],
   "source": [
    "train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "0YQ-muEM_CLP",
    "outputId": "5f127e3e-fb73-4446-bc9b-bd741fc8e76c"
   },
   "outputs": [],
   "source": [
    "#sentiment value 0\n",
    "sentiment_0 = train[train['sentiment'] == 0]\n",
    "sentiment_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "PJ-odjTc_Em3",
    "outputId": "94c9dd3d-2361-4959-d7c7-f9695253666a"
   },
   "outputs": [],
   "source": [
    "#sentiment value 1\n",
    "sentiment_1 = train[train['sentiment'] == 1]\n",
    "sentiment_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "E-V5xknW_Iso",
    "outputId": "013cd94d-cc81-485f-d967-290efb51f589"
   },
   "outputs": [],
   "source": [
    "#sentiment value 2\n",
    "sentiment_2 = train[train['sentiment'] == 2]\n",
    "sentiment_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "3kZdC3oa_MUG",
    "outputId": "6a026f06-203f-43cf-9a60-a26ab2ad0134"
   },
   "outputs": [],
   "source": [
    "#sentiment value -1\n",
    "sentiment__1 = train[train['sentiment'] == -1]\n",
    "sentiment__1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENI7R0f2--jd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VqeCRDaVxXY"
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "- A detailed section will be added..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gsz9laVVVxXY",
    "outputId": "4931ccae-d17c-44cb-c7b0-4c785ed25714"
   },
   "outputs": [],
   "source": [
    "train[\"sentiment\"].plot.hist()\n",
    "# set title and axis labels\n",
    "plt.suptitle('Sentiments Frequency Count', x=0.5, y=1.05, ha='center', fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "xRSsl6fLVxXc",
    "outputId": "162c4f3e-3b6e-4ce5-ae46-e2e10da4841c"
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "\n",
    "words = train['message']\n",
    "allwords = []\n",
    "for wordlist in words:\n",
    "    allwords += wordlist\n",
    "    \n",
    "mostcommon = FreqDist(allwords).most_common(1000)\n",
    "wordcloud = WordCloud(width=1000, height=800, background_color='black').generate(str(mostcommon))\n",
    "fig = plt.figure(figsize=(30,10), facecolor='white')\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "DJ9AdyFWVxXh",
    "outputId": "acdd9ff7-ad25-46c1-96dd-8c0def252ed1"
   },
   "outputs": [],
   "source": [
    "#Compare the sentiment analysis \n",
    "train2 = pd.read_csv('train.csv')\n",
    "from textblob import TextBlob\n",
    "train['sentiment_2']=train2['message'].apply(lambda x:TextBlob(x).sentiment.polarity)\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('Sentiment', fontsize=50)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.ylabel('Frequency', fontsize=50)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.hist(train['sentiment_2'], bins=50)\n",
    "plt.title('Sentiment Distribution', fontsize=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7kXdKDwDVxXl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DirFYvSmVxXo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FHHxdbTVxXr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GG1DAteOVxYC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_iu53ybdVxYJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9HLGvDNVxYM"
   },
   "source": [
    "<a id='basemodels'></a>\n",
    "# Classification Models\n",
    "We're going to look at the following models,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sep2TCWeVxYN"
   },
   "source": [
    "*  Decision Tree Classifier<a id='DS'></a>\n",
    "*  RandomForest Classifier<a id='random'></a>\n",
    "*  LinearSVC(Support Vector Classifier)<a id='svc'></a>\n",
    "*  LGBMClassifier(Light Gradient Boosting Machine Classifier)<a id='LGBM'></a>\n",
    "*  Logistic Regression\n",
    "*  Stochastic\n",
    "*  Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TPRVVKQVxYO"
   },
   "source": [
    "<a id='tree'></a>\n",
    "## Tree-based Models for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rdfD0TkVxYO"
   },
   "source": [
    "<a id='DC'></a>\n",
    "### Decision Tree Classifier\n",
    "\n",
    "![1*bcLAJfWN2GpVQNTVOCrrvw.png](https://miro.medium.com/max/688/1*bcLAJfWN2GpVQNTVOCrrvw.png)\n",
    "Decision Trees (DTs) are  non-parametric supervised learning methods used for classification and regression. Decision trees learn from data to approximate a sine curve with a set of if-then-else decision rules. The deeper the tree, the more complex the decision rules and the fitter the model.\n",
    "\n",
    "Decision tree builds classification or regression models in the form of a tree structure. It breaks down data by partitioning it into subsets after each decision while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. A decision node has two or more branches. Leaf node represents a classification or decision. The topmost decision node in a tree which corresponds to the best predictor called root node. Decision trees can handle both categorical and numerical data.\n",
    "\n",
    "Visual representation of a `Decision Tree`\n",
    "![1*WerHJ14JQAd3j8ASaVjAhw.jpeg](https://miro.medium.com/max/963/1*WerHJ14JQAd3j8ASaVjAhw.jpeg)\n",
    "\n",
    "\n",
    "Decision trees are prone to overfitting. Overfitting happens when the learning algorithm continues to develop hypotheses that reduce training set error at the cost of an increased test set error; One method to tackle overfitting in decision trees is by **prunning**.\n",
    "There are several approaches used to avoid overfitting in building decision trees namely, \t\t\n",
    "- Pre-pruning that stops growing the tree earlier, before it perfectly classifies the training set.\n",
    "- Post-pruning that allows the tree to perfectly classify the training set, and then post prune the tree. \n",
    "Practically, the second approach of post-pruning overfit trees is more successful because it is not easy to precisely estimate when to stop growing the tree.\n",
    "\n",
    "Decision Trees are building blocks for the next machine learning method we will look into, which is the **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL8jpnPxVxYP"
   },
   "source": [
    "<a id='random'></a>\n",
    "### Random Forest Classifier\n",
    "`Random forest` is a supervised learning algorithm that can be used both for classification and regression. A forest is comprised of a number of individual trees. It is said that the more trees it has, the more robust a forest is, unlike decision trees `Random Forest`  prevents overfitting by creating trees on random subsets  \n",
    "\n",
    "The Random forest algorithm works in four steps\n",
    "\n",
    " 1. Selects a number of random samples from a given dataset\n",
    " 2. Construct a decision tree for each sample and get a prediction result from each decision tree\n",
    " 3. Perform a vote for each predicted result.\n",
    " 4. Select the prediction result with the most votes as the final prediction.\n",
    "\n",
    "a visual representation of a Random Forest classifier is seen in the diagram below\n",
    "![voting_dnjweq.jpg](https://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526467744/voting_dnjweq.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCplaYUjVxYQ"
   },
   "source": [
    "## Support Vector Classification(LinearSVC)\n",
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or a hyperplane which separates the data into classes as seen in the diagram below\n",
    "\n",
    "![1*dh0lzq0QNCOyRlX1Ot4Vow.jpeg](https://miro.medium.com/max/963/1*dh0lzq0QNCOyRlX1Ot4Vow.jpeg)\n",
    "\n",
    "To better explain the concept of `SVM` we will look at a case of two classes.\n",
    "\n",
    "**To find the best line seperating the classes**\n",
    "\n",
    "The `SVM` algorithm finds the points closest to the line from both the classes.These points are called support vectors, then it compute the distance between the line and the support vectors, This distance is called the margin. Our goal is to maximize the margin.\n",
    "\n",
    "In a case for more than two classes the goal is to find the the best hyperplane that seperates the classes.\n",
    "The hyperplane for which the margin is maximum is the optimal hyperplane.\n",
    "\n",
    "Below is a visual representation of how `SVMs` work\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"https://miro.medium.com/max/880/1*VDATmWG1E1ZNg7hdasOh5g.png\" width=\"300\" />\n",
    "  <img src=\"https://miro.medium.com/max/880/1*AMR3v-jCvUMXPUtQskzxmQ.png\" width=\"300\" />\n",
    "  <img src=\"https://miro.medium.com/max/880/1*irg_jfdAar9gfe0j-Q04vQ.png\" width=\"300\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QJEmvWVVxYQ"
   },
   "source": [
    "## Light Gradient Boosting Machine(LightGBM)\n",
    "LightGBM is a gradient boosting framework that also uses a tree based learning algorithm. LightGBM differes from other tree based algorithms in the sense that it grows trees vertifically while other algorithms grow them horizontally, this means that Light GBM grows trees leaf-wise while other algorithm grow level-wise.\n",
    "\n",
    "LightGBM will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n",
    "The diagrams below explain the implementation of LightGBM and other boosting algorithms\n",
    "\n",
    "\n",
    "How Light GBM works![1*AZsSoXb8lc5N6mnhqX5JCg.png](https://miro.medium.com/max/875/1*AZsSoXb8lc5N6mnhqX5JCg.png)\n",
    "\n",
    "How other tree based algorithms work\n",
    "![1*whSa8rY4sgFQj1rEcWr8Ag.png](https://miro.medium.com/max/875/1*whSa8rY4sgFQj1rEcWr8Ag.png)\n",
    "\n",
    "some advantages of LightGBM framework include\n",
    "- Faster training speed and higher efficiency.\n",
    "- Lower memory usage.\n",
    "- Better accuracy.\n",
    "- Support of parallel and GPU learning.\n",
    "- Capable of handling large-scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEvOPNT8P4Aj"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUkE3h0eP4Al"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1k34c5TP4Aq"
   },
   "source": [
    "# Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fsrMxgPxP4Ar"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a8bUh8GP4Aw"
   },
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy-NLeW0P4Ax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeQ3Eme3P4A5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ekydnt2VxYR"
   },
   "source": [
    "# Creating our X and y Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO2j5iKDVxYR"
   },
   "outputs": [],
   "source": [
    "X = train_data['message']\n",
    "y = train_data['sentiment']\n",
    "X_test = test_data['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvDcaHe-VxYU"
   },
   "source": [
    "# Splitting data into train and validation sets\n",
    "\n",
    "Separating data into training and validation sets is an important part of evaluating our models. \n",
    "In our case we will randomly split the train data into 70% train and 30% validation. \n",
    "After our model is trained with the train data we then use it to make predictions for the target using the validation set,Because the data in the validation set already contains known values for the target variable this will make it easy  for us to asses our model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WbV6jZAVxYU"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into 70% train and 30% validation set\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=.3,shuffle=True, stratify=y, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25NQkdQ6VxYX"
   },
   "source": [
    "<a id='feature_engineering'></a>\n",
    "# Feature Engineering\n",
    "We will be looking at one of feature selection in text data namely the `tfidfVectorizer`\n",
    "\n",
    "<a id='tfidf'></a>\n",
    "`TF-IDF` stands for Term Frequency â€” Inverse Document Frequency and is a statistic that aims to better define how important a word is for a document, while also taking into account the relation to other documents from the same corpus.\n",
    "This is performed by looking at how many times a word appears into a document while also paying attention to how many times the same word appears in other documents in the corpus.\n",
    "`vocabulary_` Is a dictionary that converts each word in the text to feature index in the matrix, each unique token gets a feature index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBUPaQ7vVxYX"
   },
   "source": [
    "<a id='Pipelines'></a>\n",
    "# Pipelines\n",
    "![cover.png](https://www.houseofbots.com/images/news/11939/cover.png)\n",
    "`Pipeline`  by definition is a tool that sequentially applies a list of transforms and a final estimator. Intermediate steps of pipeline implement fit and transform methods and the final estimator only needs to implement fit. In our case pipelines will help us tranform the train, validation and test data as well as train our models.\n",
    "\n",
    "Since our models can only process numerical data our first step is to build a pipeline that converts text data into numeric data, In this notebook we will be focusing on two methods of feature engineering, which we will use to convert text data to numeric data, namely TfidfVectorizer and Word2Vec, then we will train our models within these pipelines\n",
    "\n",
    "We will be building pipelines with features generated using `tfidfVectorizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xq1ZK5_P4BI"
   },
   "source": [
    "<a id='classifiers'></a>\n",
    "## Building classification  pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVlNXJMXP4BI"
   },
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier Pipeline\n",
    "tree = Pipeline([('tfidf', TfidfVectorizer()),('tree', DecisionTreeClassifier()),])\n",
    "\n",
    "\n",
    "# RandomForestClassifier Pipeline\n",
    "rfc = Pipeline([('tfidf', TfidfVectorizer()), ('rfc', RandomForestClassifier())])\n",
    "\n",
    "\n",
    "# LinearSVC Pipeline\n",
    "Lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('scv', LinearSVC()),])\n",
    " \n",
    "# LGBMClassifier Pipeline\n",
    "lgbm = Pipeline([('tfidf', TfidfVectorizer()), ('lgbm', LGBMClassifier())])\n",
    "\n",
    "# Logistic Regression pipeline\n",
    "logreg = Pipeline([('tfidf', TfidfVectorizer()),('logistic', LogisticRegression()),])\n",
    "\n",
    "\n",
    "# SGD Classifier pipeline\n",
    "SGD = Pipeline([('tfidf', TfidfVectorizer()), ('SGD', SGDClassifier())])\n",
    "\n",
    "# Support Vector Classifier Pipeline\n",
    "svc = Pipeline([('tfidf', TfidfVectorizer()), ('SVC', SVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tFzIx1OVxYY"
   },
   "source": [
    "<a id='raw_tweets'></a>\n",
    "## Training models\n",
    "Each model is trained using it's custom pipeline which will take raw text data turn it into numeric data and initial the classifier with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJf305FeVxYZ",
    "outputId": "90dd3d4e-d7be-4f59-8033-04706de913d5"
   },
   "outputs": [],
   "source": [
    "# training the decision tree pipeline\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# training the RandomForest pipleline\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# training the LinearSVC pipeline\n",
    "Lsvc.fit(X_train, y_train)  \n",
    "\n",
    "# training the LGBMClassifier Pipleine\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# training the logistic regression pipeline\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# training the SGD Classifier\n",
    "SGD.fit(X_train, y_train)\n",
    "\n",
    "# training the support vector classifier\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P_foBaRVxYY"
   },
   "source": [
    "<a id='model_eval'></a>\n",
    "# Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaU-hg0VVxYc"
   },
   "source": [
    "<a id='model_eval'></a>\n",
    "## Model evalution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C81w2pNWP4BS"
   },
   "source": [
    "### Performance Metrics for model evaluation\n",
    "\n",
    "We will evaluate our models using the the F1 Score which is the number of true instances for each label.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} $$\n",
    "\n",
    "#### Recall\n",
    "\n",
    "The recall is intuitively the ability of the classifier to find all the positive samples\n",
    "\n",
    "$$ Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}$$\n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "Weighted average of precision and recall. \n",
    "\n",
    "$$F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igVxBmmqVxYd"
   },
   "source": [
    "To evaluate the base models we first start with making predictions for the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4lNVDl8VxYd"
   },
   "outputs": [],
   "source": [
    "# Making validations set predicions\n",
    "\n",
    "tree_prediction = tree.predict(X_val) # DecisionTreeClassifier predictions\n",
    "rfc_prediction = rfc.predict(X_val) # RandomForestClassifier predictions\n",
    "Lsvc_prediction = Lsvc.predict(X_val) # LinearSVClassifier Predictions\n",
    "lgbm_prediction = lgbm.predict(X_val) # LGBMClassifier Model predictions\n",
    "logreg_prediction = logreg.predict(X_val) # Logistic regression predictions\n",
    "SGD_prediction = SGD.predict(X_val) # SGD Classifier predictions\n",
    "SVC_prediction = svc.predict(X_val) # Support vector machine predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkIFNzOcVxYi"
   },
   "source": [
    "### Evalution of DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYGW9CwtP4BW",
    "outputId": "f86599d9-fb2d-49c5-f547-a07e2d1d4a56"
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_val, tree_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgANXU_IP4Ba"
   },
   "source": [
    "### Key Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHPedbjoP4Ba"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "EInmFVZeP4Be",
    "outputId": "80b009c1-785b-47d1-a825-386fcba5739d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\nDecision Tree\\n', classification_report(y_val, tree_prediction))\n",
    "plot_confusion_matrix(y_val, tree_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('Decision Tree Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwhX1QeaP4Bi"
   },
   "source": [
    "### Key Observations\n",
    "\n",
    "A Classification report is used to measure the quality of predictions from a classification algorithm.\n",
    "\n",
    "+ Anti Climate Change \n",
    "+ Neutral \n",
    "+ Pro\n",
    "+ News\n",
    "\n",
    "\n",
    "The confusion matrix heatmap shows the recall score for each sentiment class.\n",
    "+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "ZeSGFIbSP4Bj",
    "outputId": "0549dce3-8cf1-41b2-bb2b-0b012d1baeab",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_tree = classification_report(y_val, tree_prediction, output_dict=True)\n",
    "df_tree = pd.DataFrame(report_tree).transpose()\n",
    "df_tree.drop(['accuracy'], inplace = True)\n",
    "df_tree.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_tree.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for Decision Tree Classiffier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgdFbugtP4Bo"
   },
   "source": [
    "### Key Observations\n",
    "The above bar graph shows the f1 score for each sentiment class using the Decision Tree classifier\n",
    "- We see that the decision tree model did a very good job at classifiying `Pro climate change` tweets, followed by `News` and `Neutral` respectively.\n",
    "- The Decision Tree classifier did a poor job at classifiying `Anti climate Change` tweets with an f1 score that is below 0.3.\n",
    "- Poor classification of `Anti climate change` tweets is expected given the imbalance in our train data where we see that `Anti climate change` tweets only account for 8% of all tweets in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyZH3cpYVxYn",
    "outputId": "e334d384-db45-40ac-9812-a84d451eb80c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the overall accuracy\n",
    "decison_tree_acc = round(accuracy_score(y_val, tree_prediction),4)\n",
    "print(f'\\nOverall Accuracy score for Decision Tree : {decison_tree_acc}')\n",
    "decision_tree_f1 = round(f1_score(y_val, tree_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted avg f1 score Decision Tree {decision_tree_f1}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z874fI_yVxY7"
   },
   "source": [
    "### Evalution of RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRIG2m6kVxY8",
    "outputId": "b11a4d3b-f9f0-4da2-ea88-1b6ea58b219d"
   },
   "outputs": [],
   "source": [
    "print('\\nRandomForestClassifier\\n', confusion_matrix(y_val, rfc_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "fW18-BLVVxZC",
    "outputId": "1d53f22c-6c0c-48c2-bcbb-cc330389cb18",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('\\nRandomForestClassifier\\n', classification_report(y_val, rfc_prediction))\n",
    "plot_confusion_matrix(y_val, rfc_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('Random Forest Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "BPp0AIuaP4B6",
    "outputId": "d5f05812-26cd-4245-af74-919b1de866fc"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_rfc = classification_report(y_val, rfc_prediction, output_dict=True)\n",
    "df_rfc = pd.DataFrame(report_rfc).transpose()\n",
    "df_rfc.drop(['accuracy'], inplace = True)\n",
    "df_rfc.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_rfc.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for Random Forest Classiffier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er25g9YzP4B7"
   },
   "source": [
    "### Key Observations\n",
    "The above bar graph shows the f1 score for each sentiment class using the Random Forest classifier\n",
    "- We see that the Random Forest model did a better job at classifiying `Pro climate change` tweeets and  `News`  comapred to the Decision tree model, with both the `Pro climate` and `News` sentimetents scoring over 0.7. and `Neutral` tweets following after that\n",
    "- The Random Forest classifier did a poor job at classifiying `Anti climate Change` tweets with an f1 score lower than the one we got using the `Decision Tree` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsd9E8YzVxZG",
    "outputId": "ac8aec6b-460f-4217-999e-17644f2490a6"
   },
   "outputs": [],
   "source": [
    "random_forest_acc = round(accuracy_score(y_val, rfc_prediction),4)\n",
    "print(f'\\nOveral accuracy score for RandomForestClassifier :{random_forest_acc}')\n",
    "random_forest_f1 = round(f1_score(y_val, rfc_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted f1 score for RandomForestClassifier : {random_forest_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeSfqWPBVxZJ"
   },
   "source": [
    "### Evaluation of LinearSVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XScGiVA9VxZK",
    "outputId": "87700337-133e-4154-95d9-bb1afea47fd3"
   },
   "outputs": [],
   "source": [
    "print('\\nLinearSVC Model\\n', confusion_matrix(y_val, Lsvc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "I2Sw7_ygVxZM",
    "outputId": "6a7ab64d-ab61-45dd-d1e3-bc66a877ef59"
   },
   "outputs": [],
   "source": [
    "print('\\nLinearSVC Model\\n', classification_report(y_val, Lsvc_prediction))\n",
    "plot_confusion_matrix(y_val, Lsvc_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('LinearSCV Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "B729si3VVxZQ",
    "outputId": "ee093d84-e4ff-43ec-9c8d-28f8c9c78fdd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_svc = classification_report(y_val, Lsvc_prediction, output_dict=True)\n",
    "df_svc = pd.DataFrame(report_svc).transpose()\n",
    "df_svc.drop(['accuracy'], inplace = True)\n",
    "df_svc.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_svc.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for LinearSVC ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_TktFvRP4CM"
   },
   "source": [
    "### Key observations\n",
    "The above bar graph shows the f1 score for each sentiment class using the LinearSVC\n",
    "- We see that the LinearSVC model did a far better job at classifiying `Pro climate change` tweeets  compared to `Decision Tree` and `RandomForest` models  with the f1 score of label 1 sentiment class of over 0.8.\n",
    "- The LinearSVC model also did a far better job at classifying `News` tweets comapred to both the Decision tree model and RandomForest model with the highest score level 2 sentiment class of over 0.75.\n",
    "- We also see aa huge improvement in the classification of `Anti climate change` tweets with an f1 score just over 0.5, increasing from just below 0.3 that we saw with the `Decision Tree` classifier \n",
    "- There was a slight improvement in the classification of `neutral` tweets with the LinearSVC, which is by far overshadowed by the improvements we see in other sentiments classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwsrGr6AVxZU",
    "outputId": "59970651-9385-49fc-ba6a-fd54ea576c05"
   },
   "outputs": [],
   "source": [
    "linearSVC_acc = round(accuracy_score(y_val, Lsvc_prediction),4)\n",
    "print(f'\\nOverall accuracy score for LinearSVC Model : {linearSVC_acc}')\n",
    "linearSVC_f1 = round(f1_score(y_val, Lsvc_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted avg f1 score for LinearSVC Model : {linearSVC_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ksQRpQUVxZW"
   },
   "source": [
    "### Evaluation of LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGySChV1VxZX",
    "outputId": "15f5a36c-9e3f-4679-f56c-bc4a8baf156d"
   },
   "outputs": [],
   "source": [
    "print('\\nLightGBM\\n', confusion_matrix(y_val, lgbm_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "7hnhF3aDVxZZ",
    "outputId": "aba6dfcf-8399-4b04-b480-f9b73cfdea0f"
   },
   "outputs": [],
   "source": [
    "print('\\nLightGBM\\n', classification_report(y_val, lgbm_prediction))\n",
    "plot_confusion_matrix(y_val, lgbm_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('LightGBM Classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "Or90IJa2VxZc",
    "outputId": "79c8e3a4-b7d3-49c8-9009-276685fc23f6"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_lgbm = classification_report(y_val, lgbm_prediction, output_dict=True)\n",
    "df_lgbm = pd.DataFrame(report_lgbm).transpose()\n",
    "df_lgbm.drop(['accuracy'], inplace = True)\n",
    "df_lgbm.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_lgbm.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for LightGBM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaI0-cBKP4CU"
   },
   "source": [
    "### Key observations\n",
    "The above bar graph shows the f1 score for each sentiment class using the LightGBM\n",
    "- Although the LightGBM model did a far better job at classifying `Pro climate tweets` and `News` compared to `Decision Tree` and `Random Forest` it is not as good as the `LinearSVC`\n",
    "- We see a slight increase in the classification of `neutral` tweets compared to the classification of `LienarSVC`\n",
    "- We see that the classification of `Anti climate change` tweets for `LightGBM` has decreased compared to `LinearSVC`, howver `LightGBM` still classifies the `Anti climate change` sentiment class better compared to the first two models we tried `Decision Tree` and `Random Forest` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLSA9n6WVxZ3",
    "outputId": "b0e59e39-3286-4d61-b95f-d5c5ba3b3ee8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lGBM_acc = round(accuracy_score(y_val, lgbm_prediction),4)\n",
    "print(f'\\nOverall accuracy score for LightGBM :{lGBM_acc}')\n",
    "lGBM_f1 = round(f1_score(y_val, lgbm_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted f1 score for LightGBM :{lGBM_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceoOX5IYP4Ca"
   },
   "source": [
    "# Evaluation of  Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-IISsBEP4Cb",
    "outputId": "6407d433-bbc0-45aa-d48b-45682b12e501"
   },
   "outputs": [],
   "source": [
    "# Report the confusion matrix\n",
    "print('\\nLogistic Regression\\n', confusion_matrix(y_val, logreg_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "RYwXQe7ZP4Cg",
    "outputId": "2e7c76b5-01b0-47fa-b35b-76af7c9e8cf5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print a classification report\n",
    "\n",
    "print('\\nLogistic Regression\\n', classification_report(y_val, logreg_prediction))\n",
    "plot_confusion_matrix(y_val, logreg_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('Logistic Regression Classification')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "CIEGBl_OP4Cl",
    "outputId": "a0b8fee9-1be4-4312-e172-91016c6f28e8"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_logreg = classification_report(y_val, logreg_prediction, output_dict=True)\n",
    "df_logreg = pd.DataFrame(report_logreg).transpose()\n",
    "df_logreg.drop(['accuracy'], inplace = True)\n",
    "df_logreg.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_logreg.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1 score per sentiment class for Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9VaJv77P4Cn",
    "outputId": "b4c67af4-21d8-4fa8-96e1-b9939748859a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the overall accuracy\n",
    "logistic_reg_acc = round(accuracy_score(y_val, logreg_prediction),4)\n",
    "print('\\nLogistic Regression accuracy Score\\n', logistic_reg_acc)\n",
    "logistic_reg_f1 = round(f1_score(y_val, logreg_prediction, average=\"weighted\"),4)\n",
    "print('\\nLogistic Regression weighted f1 score\\n', logistic_reg_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTEr76e0P4Cq"
   },
   "source": [
    "# Evaluation of SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p31Fz8JeP4Cq",
    "outputId": "fa86cada-2bb2-4208-8131-8300fbd9dde3"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for the random forest classifier\n",
    "print('\\nSGD Classifier\\n', confusion_matrix(y_val, SGD_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "dcPvU0I3P4Cw",
    "outputId": "8effd455-8830-47e6-e940-a904bcc1c95c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The classification report \n",
    "print('\\nSGD Classifier  Classification report :\\n', classification_report(y_val, SGD_prediction))\n",
    "plot_confusion_matrix(y_val, SGD_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('Logistic Regression Classification')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "JnU9vtBtP4Cy",
    "outputId": "7147e348-02f9-43d1-cecd-b4d1da0924d7"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_sgd = classification_report(y_val, SGD_prediction, output_dict=True)\n",
    "df_sgd = pd.DataFrame(report_sgd).transpose()\n",
    "df_sgd.drop(['accuracy'], inplace = True)\n",
    "df_sgd.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_sgd.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for SGD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mRVkOfPqP4C1",
    "outputId": "5be05702-378a-4347-f576-19521fa69da3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "sgd_acc = round(accuracy_score(y_val, SGD_prediction),4)\n",
    "print('\\nSGD Classifier accuracy Score :\\n', sgd_acc)\n",
    "\n",
    "# Checking the f1_score report for the decison tree model\n",
    "sgd_f1 = round(f1_score(y_val, SGD_prediction, average=\"weighted\"),4)\n",
    "print('\\nSGD weighted avg f1_score :\\n', sgd_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Eun9nRLP4C5"
   },
   "source": [
    "# Support Vector Classfifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xuFH6ziRP4C5",
    "outputId": "19812ee9-f1d7-47f3-a668-e26c6c333e2f"
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for the random forest classifier\n",
    "print('\\nSupport Vector Classifier\\n', confusion_matrix(y_val, SVC_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "tD7q2u7KP4C7",
    "outputId": "7524691f-cb86-4266-c624-286bcd922628",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The classification report \n",
    "print('\\nSupport Vector Classifier  Classification report :\\n', classification_report(y_val, SVC_prediction))\n",
    "plot_confusion_matrix(y_val, SVC_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "plt.title('Support Vector Classification')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "STVzvO4VP4C8",
    "outputId": "a3819b7f-022b-46db-9338-138eb6dd2138"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_svc = classification_report(y_val, SVC_prediction, output_dict=True)\n",
    "df_SVC = pd.DataFrame(report_svc).transpose()\n",
    "df_SVC.drop(['accuracy'], inplace = True)\n",
    "df_SVC.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_SVC.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for SVC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVoT3MGaP4C-"
   },
   "source": [
    "### Key observations\n",
    "The above bar graph shows the f1 score for each sentiment class using the Support Vector Classifier(SVC)\n",
    "- Much like the `LinearSVC` we see that the  the `SVC` does a really good job at classifying `Pro climate change` sentiment class with a score of 0.8, followed by the `News` sentiment class with an f1 score of over 0.75.\n",
    "- Similar to most of the models we've tested thus far the  `Support Vector Classifer` struggled with classifying the `anti climate change` sentiment, scoring just over 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUCd0nxiP4DA",
    "outputId": "9f422d45-1d92-445f-8aa9-85843c0bb238"
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "svc_acc = round(accuracy_score(y_val, SVC_prediction),4)\n",
    "print(f'\\nSupport Vector Classifier accuracy Score :{svc_acc}')\n",
    "svc_f1 = round(f1_score(y_val, SVC_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nSupport Vector Classifier weighted avg f1_score :{svc_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-nPqXDaVxZ8"
   },
   "source": [
    "### Model Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnFrxENfP4DD"
   },
   "source": [
    "Model comparison by accuracy and macro f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "maHewyvWVxZ8",
    "outputId": "dcc66806-77df-4bda-cc4e-8149da52e018"
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe with our models and their performances metrics\n",
    "classifier_scores = {'Classifiers':['Decision Tree', 'Random Forest','LinearSVC',\n",
    "                                    'LGBM','Logistic Regression','Stochastic Gradient Descent','Support Vector Classifier'],\n",
    "                    'Accuracy':[decison_tree_acc,random_forest_acc,\n",
    "                                linearSVC_acc,lGBM_acc,logistic_reg_acc, sgd_acc, svc_f1],\n",
    "                     'Weighted avg f1 Score':[decision_tree_f1,random_forest_f1,\n",
    "                                       linearSVC_f1,lGBM_f1,logistic_reg_f1, sgd_f1, svc_f1]}\n",
    "df= pd.DataFrame(classifier_scores)\n",
    "df.sort_values(by=['Accuracy'],ascending=True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "IUyerjeFVxaF",
    "outputId": "2c7b7bcc-3396-4752-e72c-f830a27f4914",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.set_index(df['Classifiers'], inplace = True)\n",
    "df.drop(['Classifiers'],axis = 1)\n",
    "df.plot(kind='barh', figsize = (8,8),colormap='winter')\n",
    "plt.xlabel('Score')\n",
    "plt.yticks(rotation = 45)\n",
    "plt.title('Classifier Perfomance')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLJkjnvhP4DH"
   },
   "source": [
    "## Key observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5F2vWWlP4DH"
   },
   "source": [
    "From the above bar graph we see comparison of all the 7 models we've attempted thus far based on their `accuracy score` and associated `wighted f1 score`\n",
    "\n",
    "- We see that our top 3 best performing models are `LinearSVC`,`Stochastic Gradient Descent` and `Logistic Regression` respectively, theres are the models will use in ensemble methods to try and improve our results\n",
    "- The `Decision Tree` classifer is the worst  at classifying the tweets with the lowest accuracy and wighted f1 scores of 0.61 and 0.60 respectivey\n",
    "\n",
    "**LinearSVC is the best performing model out of all 7 models that we've tried thus far with an accuracy score of 0.74 and a weighted f1 score of 0.72**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iYK7oyvP4DI"
   },
   "source": [
    "# Ensemble Methods\n",
    "\n",
    "Ensemble learning in machine learning is the practice of combining multiple models to try and achieve higher overall model performance. In general, ensembles consist of multiple **heterogeneous or homogeneous** models trained on the same dataset. Each of these models is used to make predictions on the same input, then these predictions are aggregated across all models in some way (e.g. by taking the mean) to produce the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCd5wjWyVxbP"
   },
   "source": [
    "<a id='ensemble'></a>\n",
    "## Heterogeneous Ensembel Method\n",
    "This type of ensemble consists of different types of models, so it can add pretty much any classification model we want, however in our case we're only going to add our top 3 best perfoming models which are, `LinearSVC, Stochastic Gradient Descent, Logistic Regression, `.\n",
    "\n",
    "The Heterogeneous ensemble method we're going to look at is the `Voting classifier`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHI4LVZaP4DJ"
   },
   "source": [
    "### Voting classifer \n",
    "Voting involves combining individual model outputs through a kind of \"[majority rule](https://en.wikipedia.org/wiki/Majority_rule)\" paradigm.\n",
    "The diagram below shows how the `Voting Classifier` works\n",
    "![ud382N9.png](https://iq.opengenus.org/content/images/2020/01/ud382N9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5oPdNfnP4DK"
   },
   "outputs": [],
   "source": [
    "# Define the models which we'll include in our ensemble. \n",
    "# We pass a list of tuples, which each have a string identifier for the\n",
    "# model (arbitrary choice), along the actual instantiated sklearn model.  \n",
    "models = [(\"LinearSVC\",Lsvc),(\"SGD\",SGD),(\"Logistric Regression\",logreg)]\n",
    "\n",
    "# Specify weights for weighted model averaging\n",
    "model_weightings = np.array([0.1,0.3,0.6])\n",
    "\n",
    "# building the voting classifier\n",
    "Voting_classifier = VotingClassifier(estimators=models,weights=model_weightings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7KY_AftnP4DO",
    "outputId": "9ee3516b-6ef3-44bd-d838-0a17e8399271",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training the voting classifier\n",
    "Voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xpj6BsaNP4DQ"
   },
   "outputs": [],
   "source": [
    "voting_prediction = Voting_classifier.predict(X_val) # Voting Classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYLvWB0kP4DR",
    "outputId": "f954000c-7ea3-4da5-c916-458becced34d"
   },
   "outputs": [],
   "source": [
    "# The classification report \n",
    "print('\\nVoting Classifier  Classification report :\\n', classification_report(y_val, voting_prediction))\n",
    "# plot_confusion_matrix(y_val, voting_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "# plt.title('Voting Classifier Classification')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1M5jiWvP4DT"
   },
   "outputs": [],
   "source": [
    "# # # Visual represetation of of the f1 score for each class\n",
    "# report_voting = classification_report(y_val, voting_prediction, output_dict=True)\n",
    "# df_voting = pd.DataFrame(report_voting).transpose()\n",
    "# df_voting.drop(['accuracy'], inplace = True)\n",
    "# df_voting.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "# df_voting.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "# plt.xlabel('f1-score')\n",
    "# plt.ylabel('Classes')\n",
    "# plt.yticks(rotation = 40)\n",
    "# plt.title('f1-score per sentiment class for the voting classifier')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmGt8id4P4DU",
    "outputId": "93b6cf2f-8132-4369-c259-7c1bebff3a7b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "voting_acc = round(accuracy_score(y_val, voting_prediction),4)\n",
    "print(f'\\nOverall accuracy for the Voting Classifier :{voting_acc}')\n",
    "voting_f1 = round(f1_score(y_val, voting_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted avg f1 score for the Voting Classifier :{voting_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q3uaqEReP4DW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heVmm9kZP4DY"
   },
   "source": [
    "## Homogeneous Ensembles\n",
    "\n",
    "These consist of the same type of model. As such, a common way to promote diversity in model performance in these cases is to control the number of predictors or portion of data supplied to each model in the ensemble. Much like what happens in a random forest.\n",
    "\n",
    "Some the most common methods for combining models in this way include **bagging** and **boosting**.\n",
    "\n",
    "### Bagging (AKA Bootstrap Aggregating)\n",
    "\n",
    "Bagging involves training the models of the ensemble on different subsets of the training data. Particularly on subsets which are **sampled with replacement** from the training data. As such, the resulting 'bag' of models are together more stable due to decreased variance error. \n",
    "\n",
    "The predictions are made by aggregating the predictions of all the models in the bag.\n",
    "![1*JksRZ1E72Rsx2s8lQbNR1w.jpeg](https://miro.medium.com/max/875/1*JksRZ1E72Rsx2s8lQbNR1w.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYa1kdhZP4DZ"
   },
   "outputs": [],
   "source": [
    "bag_class= Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('bag', BaggingClassifier(base_estimator = LinearSVC())),])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWrj4D4MP4Db",
    "outputId": "fae423d0-456f-43c2-e831-ca91e1502ce3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bag_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDpGQNliP4Dd"
   },
   "outputs": [],
   "source": [
    "bag_prediction = bag_class.predict(X_val) # Bagging Classifier predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kHMprdJdP4Dh",
    "outputId": "f2271bd0-72d2-42f5-f1df-9d1c0f0fdc46"
   },
   "outputs": [],
   "source": [
    "# The classification report \n",
    "print('\\nBagging Classifier  Classification report :\\n', classification_report(y_val, bag_prediction))\n",
    "# plot_confusion_matrix(y_val, voting_prediction, normalize=True,figsize=(8,8),cmap='Blues')\n",
    "# plt.title('Bagging Classifier Classification')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxyqgr1_P4Dj"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "# report_bagging = classification_report(y_val, bag_prediction, output_dict=True)\n",
    "# df_bag = pd.DataFrame(report_bagging).transpose()\n",
    "# df_bag.drop(['accuracy'], inplace = True)\n",
    "# df_bag.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "# df_bag.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "# plt.xlabel('f1-score')\n",
    "# plt.ylabel('Classes')\n",
    "# plt.yticks(rotation = 40)\n",
    "# plt.title('f1-score per sentiment class for the voting classifier')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytR1fMaEP4Dm",
    "outputId": "2f55fb7c-877d-43c7-ecb9-881a25b8ff96"
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "bag_acc = round(accuracy_score(y_val, bag_prediction),4)\n",
    "print(f'\\nBagging Classifier accuracy Score :{bag_acc}')\n",
    "bag_f1 = round(f1_score(y_val, bag_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nBagging Classifier weighted avg f1 score :{bag_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sr8XEUmUVxbQ"
   },
   "source": [
    "<a id='hy_tunning'></a>\n",
    "# Hyperparameter Tunning\n",
    "we will search for the best hyperparameters for our models using a GridSeachCV method.\n",
    "\n",
    "* Models we will perform hyperparameter tunning on\n",
    "  * LinearSVC\n",
    "  * Logistic Regression\n",
    "  * Support Vector Classifier\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0V1GnslP4Dt"
   },
   "source": [
    "The caveat of using pipelines to build our models is that we can't easily get the parameters for our models as such to perfom hyperparameter tunning and obtain the best parameters for our modeks we wont be using the pipelines, this means we would have to convert raw text data to numeric using `TifidfVectorizer` independently from building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fndEuS0LP4Du"
   },
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "X_train_new= X_train.copy\n",
    "X_val_new = X_val.copy()\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, smooth_idf = True, max_df = 0.3, min_df = 5, ngram_range = (1, 2))\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_new = vectorizer.transform(X_train)\n",
    "X_val_new = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cnd3nb77P4Dz"
   },
   "source": [
    "## Tuning LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkVE3YQBP4Dz",
    "outputId": "779ec8d4-40b6-4afe-94a5-b8cb103c8d3d"
   },
   "outputs": [],
   "source": [
    "# The hyperprarameter gridsearch for the LinearSVC is purposefully commented out because \n",
    "# it perfoms 5 folds for each of the 9 candidates totalling in 45 fits, this GridSearch code took 27 minutes to complete\n",
    "\n",
    "#  we have saved the resulting model as a pickle file for convinience\n",
    "\n",
    "\n",
    "'''\n",
    "param_grid = {'C': [0.2,0.3,0.4,0.5,1.0,3,3.01,10, 100]}\n",
    "# grid_lsvc = GridSearchCV(LinearSVC(),param_grid,refit=True,verbose=2)\n",
    "# grid_lsvc.fit(X_train_new,y_train)\n",
    "\n",
    "grid_lsvc = Pipeline([('tfidf', TfidfVectorizer()), ('grid', GridSearchCV(SVC(),\n",
    "                                                                     param_grid,refit=True,verbose=2))])\n",
    "                                                                     \n",
    "\n",
    "grid_lsvc.fit(X_train,y_train)\n",
    "\n",
    "# Saving the model\n",
    "import pickle\n",
    "model_save_path = 'LinearSVC.pkl'\n",
    "with open(model_save_path, 'wb') as file:\n",
    "    pickle.dump(grid_lsvc, file)\n",
    "    \n",
    "''' \n",
    " # loading the saved Logistic Regression model\n",
    "model_load_path = 'LinearSVC.pkl'\n",
    "with open(model_load_path, 'rb') as file:\n",
    "    grid_lsvc=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyJT9HLDVjSo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zkg9KzM2P4D2",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obsxp5cEP4D4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuned_lsvc_predictions = grid_lsvc.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-ZuaelaP4D-",
    "outputId": "b7157d19-f1d4-430b-8990-dea9732dc8de"
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "tuned_lsvc_acc = round(accuracy_score(y_val, tuned_lsvc_predictions),4)\n",
    "print(f'\\nOverall accuracy score for LinearSVC :{tuned_lsvc_acc}')\n",
    "tuned_lsvc_f1 = round(f1_score(y_val, tuned_lsvc_predictions, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted f1 score for LinearSVC :{tuned_lsvc_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTyIE-HAP4EB"
   },
   "source": [
    "# Tuning Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InIzaPxqP4EC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The hyperprarameter gridsearch for the logistic regression model is purposefully commented out because \n",
    "# it perfoms 5 folds for each of the 50 candidates totalling in 250 fits, this GridSearch  code took 3.6 minutes to complete\n",
    "#  we have saved the resulting model as a pickle file\n",
    "\n",
    "\n",
    "'''\n",
    "param_grid = [\n",
    "    {'penalty' : [ 'l2'],\n",
    "    'C' : np.logspace(-4, 4, 50),\n",
    "    'solver' : ['lbfgs']},]\n",
    "\n",
    "Logistic_reg_grid = GridSearchCV(LogisticRegression(),param_grid,refit=True,verbose=2)\n",
    "Logistic_reg_grid.fit(X_train_new, y_train)\n",
    "\n",
    "\n",
    "# Saving the model\n",
    "import pickle\n",
    "model_save_path = 'LogisticReg.pkl'\n",
    "with open(model_save_path, 'wb') as file:\n",
    "    pickle.dump(logistic_grid, file)\n",
    "    \n",
    "  \n",
    " # loading the saved Logistic Regression model\n",
    "model_load_path = 'LogisticReg.pkl'\n",
    "with open(model_load_path, 'rb') as file:\n",
    "    Logistic_reg_tuned=pickle.load(file)\n",
    "    \n",
    "    \n",
    "best_parameters = {'C': 1000, 'penalty': 'l2', multi_class='ovr','solver': 'saga'}\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# Retraining the Logistic Regresion model with best parameters                     \n",
    "logreg_tunned = Pipeline([('tfidf', TfidfVectorizer()),('logistic', LogisticRegression(C=1000, multi_class='ovr', \n",
    "                                                                          solver='saga', random_state=11, max_iter=10)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7bOHfbkP4EF",
    "outputId": "b4cf6bd6-23cd-4d56-f1f5-7de4c6123480",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logreg_tunned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGo4NPD2P4EI",
    "outputId": "3b266707-449b-4923-eebd-d0a99c0a7f49"
   },
   "outputs": [],
   "source": [
    "tunned_logreg_acc = round(accuracy_score(y_val,logreg_tunned.predict(X_val)),4)\n",
    "print(f'Overall accuracy score Tuned Logistic Regression accuracy Score :{tunned_logreg_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVqL1neAP4EL",
    "outputId": "e1fac4ab-6886-4df6-e73e-9b93fb79f314"
   },
   "outputs": [],
   "source": [
    "tunned_logreg_f1 = round(f1_score(y_val, logreg_tunned.predict(X_val), average = 'weighted'),4)\n",
    "print(f'Weighted avg f1 score for Tuned Logistic Regression Classifier :{tunned_logreg_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1QDTTlaP4EO"
   },
   "source": [
    "## Tuning Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNuEdRneP4EO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is purposefully commnted out because it Fits 5 folds for each of 72 candidates, totalling 360 fits\n",
    "# the total runtime for this gridserch was 186 Minutes\n",
    "# we have saved the model in a pickle file\n",
    "\n",
    "'''\n",
    "\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\n",
    "\n",
    "grid = Pipeline([('tfidf', TfidfVectorizer()), ('grid', GridSearchCV(SVC(),\n",
    "                                                                     param_grid,refit=True,verbose=2))])\n",
    "                                                                     \n",
    "\n",
    "\n",
    "param_grid = {'C': [0.1,1,3,3.01,10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "grid = Pipeline([('tfidf', TfidfVectorizer()), ('grid', GridSearchCV(SVC(),\n",
    "                                                                     param_grid,refit=True,verbose=2))])\n",
    "\n",
    "\n",
    "                                                                     \n",
    "                                                                                                                                 \n",
    "# training the tunned model\n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "\n",
    "best_params = {'memory': None,\n",
    " 'steps': [('tfidf',\n",
    "   TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
    "                   dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
    "                   input='content', lowercase=True, max_df=1.0, max_features=None,\n",
    "                   min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
    "                   smooth_idf=True, stop_words=None, strip_accents=None,\n",
    "                   sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "                   tokenizer=None, use_idf=True, vocabulary=None)),\n",
    "  ('grid',\n",
    "   GridSearchCV(cv=None, error_score=nan,\n",
    "                estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
    "                              class_weight=None, coef0=0.0,\n",
    "                              decision_function_shape='ovr', degree=3,\n",
    "                              gamma='scale', kernel='rbf', max_iter=-1,\n",
    "                              probability=False, random_state=None, shrinking=True,\n",
    "                              tol=0.001, verbose=False),\n",
    "                iid='deprecated', n_jobs=None,\n",
    "                param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
    "                            'kernel': ['rbf', 'poly', 'sigmoid']},\n",
    "                pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
    "                scoring=None, verbose=2))]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Saving the model\n",
    "import pickle\n",
    "model_save_path = 'SVCGrid.pkl'\n",
    "with open(model_save_path, 'wb') as file:\n",
    "  pickle.dump(grid, file)\n",
    "  \n",
    "'''\n",
    "\n",
    "# loading the saved model\n",
    "model_load_path = 'SVCGrid.pkl'\n",
    "with open(model_load_path, 'rb') as file:\n",
    "    TunedSVC=pickle.load(file)\n",
    "TunedSVC_prediction =TunedSVC.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2Q303JXP4ER",
    "outputId": "84fbf8f4-b7a6-4f75-f7ed-9d14dc257569"
   },
   "outputs": [],
   "source": [
    "# Checking the accuracy score\n",
    "tunned_svc_acc = round(accuracy_score(y_val, TunedSVC_prediction),4)\n",
    "print(f'\\nOverall accuracy score for Tuned Support Vector Classifier accuracy Score :{tunned_svc_acc}')\n",
    "tunned_svc_f1 = round(f1_score(y_val, TunedSVC_prediction, average=\"weighted\"),4)\n",
    "print(f'\\nWeighted avg f1 score for Tuned Support Vector Classifier :{tunned_svc_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJhx5GxfP4EV"
   },
   "source": [
    "# Final model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKb_zxz7P4EV"
   },
   "source": [
    "Comparing all the models we've build so far to choose the best performing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "k9hR3nSnP4EV",
    "outputId": "a30a5edc-2762-429a-ceeb-779436cde710"
   },
   "outputs": [],
   "source": [
    "classifier_scores = {'Classifiers':['Decision Tree', 'Random Forest','LinearSVC',\n",
    "                                    'LGBM','Logistic Regression','Stochastic Gradient Descent',\n",
    "                                    'Support Vector Classifier', 'Voting Classifer','Bagging Classifier',\n",
    "                                    'Tunned_LinearSVC','Tunned LogisticReg','Tunned_SVC'],\n",
    "                    'Accuracy':[decison_tree_acc,random_forest_acc,\n",
    "                                linearSVC_acc,lGBM_acc,logistic_reg_acc, sgd_acc, svc_f1, voting_acc,\n",
    "                                bag_acc,tuned_lsvc_acc ,tunned_logreg_acc,\n",
    "                                tunned_svc_acc],\n",
    "                     'Weighted avg f1 Score':[decision_tree_f1,random_forest_f1,\n",
    "                                       linearSVC_f1,lGBM_f1,logistic_reg_f1, sgd_f1, svc_f1,\n",
    "                                              voting_f1, bag_f1, tuned_lsvc_f1 ,tunned_logreg_f1, \n",
    "                                              tunned_svc_f1]}\n",
    "df= pd.DataFrame(classifier_scores)\n",
    "df.sort_values(by=['Accuracy'],ascending=True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "7rLMA2o4P4Ea",
    "outputId": "4baa3e62-43ae-4abd-c14f-c63acd03927a"
   },
   "outputs": [],
   "source": [
    "df.set_index(df['Classifiers'], inplace = True)\n",
    "df.drop(['Classifiers'],axis = 1)\n",
    "df.plot(kind='barh', figsize = (8,8),colormap='winter')\n",
    "plt.xlabel('Score')\n",
    "plt.yticks(rotation = 45)\n",
    "plt.title('Classifier Perfomance')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESAaNa16P4Ec"
   },
   "source": [
    "We have build a total of 11 models in this notebook out of all the models we've build, We see that the best performing model is the tunned Support Vector Classifer with the best accuracy score of 0.82 and the best weighted f1 score  of 82.\n",
    "\n",
    "We will be using the **Support Vector Classifer** to make the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THVLBAANP4Ed"
   },
   "source": [
    "## Final evaluation of our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUrymORaP4Ed",
    "outputId": "9a77035a-9b88-4425-b884-6eff0f5ad332"
   },
   "outputs": [],
   "source": [
    "print('classfication report for our best model\\n',classification_report(y_val, TunedSVC.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "7mUz-pd8P4Eg",
    "outputId": "5a8dc3a8-3874-49bf-cd7d-101933a872b1"
   },
   "outputs": [],
   "source": [
    "# # Visual represetation of of the f1 score for each class\n",
    "report_tuned_svc = classification_report(y_val, TunedSVC_prediction, output_dict=True)\n",
    "df_tuned_svc = pd.DataFrame(report_tuned_svc).transpose()\n",
    "df_tuned_svc.drop(['accuracy'], inplace = True)\n",
    "df_tuned_svc.sort_values(by=['f1-score'],ascending=True, inplace = True)\n",
    "df_tuned_svc.drop(['weighted avg','macro avg'])['f1-score'].plot(kind='barh', figsize = (8,8))\n",
    "plt.xlabel('f1-score')\n",
    "plt.ylabel('Classes')\n",
    "plt.yticks(rotation = 40)\n",
    "plt.title('f1-score per sentiment class for tunned SVC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz5J-G4dP4Eh"
   },
   "source": [
    "The above bar graph shows the f1 score for each sentiment class our best model\n",
    "- The Support Vector Classifier is by far our best performing model, achieving f1 score of 0.87 for `Pro climate change` sentiment class, followed by `News` and `Anti` Climate sentiment classes with f1 scores of 0.84 and 0.70 respectively, which is quite impressive given that all our models perfomed poorly when it comes to classifying `anti climate change` sentiment class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzXIiax0P4Ei"
   },
   "source": [
    "### ROC Curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZ9VzhqWP4Ei"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "id": "k6ApcLcjP4Ej",
    "outputId": "3c70511f-6962-44b5-8cf9-6bae44a95994"
   },
   "outputs": [],
   "source": [
    "OneVsRest =  OneVsRestClassifier(SVC(class_weight='balanced'))\n",
    "y_train_binarized = label_binarize(y_train, classes=[-1, 0, 1, 2])\n",
    "y_val_binarized = label_binarize(y_val, classes=[-1, 0, 1, 2])\n",
    "OneVsRest.fit(X_train_new, y_train_binarized)\n",
    "y_prob = OneVsRest.decision_function(X_val_new)\n",
    "plot_roc(y_val, y_prob,figsize=(10,10),cmap='cool')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GDw9ev1P4El"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vKyF-gdVxbQ"
   },
   "source": [
    "<a id='predictions'></a>\n",
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJnTwKcZP4Em"
   },
   "outputs": [],
   "source": [
    "y_pred = TunedSVC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mD2oTGlP4Eo",
    "outputId": "b4b5261c-fa18-4527-94d6-b2002d81bd22"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIL7JdkiVxbY"
   },
   "outputs": [],
   "source": [
    "test['sentiment'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_sR1mguVxbc"
   },
   "outputs": [],
   "source": [
    "#test[['tweetid','sentiment']].to_csv('SubmissionCSV.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "kktvVH8YP4Eu",
    "outputId": "80e4837d-0910-4f40-dee8-06894c0eb54e"
   },
   "outputs": [],
   "source": [
    "test[['tweetid','sentiment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDR87NidP4Ey"
   },
   "source": [
    "# Closing the comet experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSkDsJzkVxbk"
   },
   "outputs": [],
   "source": [
    "# close the experiment\n",
    "#experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4t8yM8YVxbp"
   },
   "outputs": [],
   "source": [
    "#experiment.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUJ4joelVxbr"
   },
   "source": [
    "<a id='conclusion'></a>\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QyzA_5hP4E9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7mpqti-Vxbr"
   },
   "source": [
    "\n",
    "<a id='appendix'></a>\n",
    "# Appendix\n",
    "* Things we did but couldnt fit anywhere in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpF8d0RHP4FE"
   },
   "source": [
    "## Hyperparameter tuning using parfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "xiKZUWStP4FE",
    "outputId": "e9d1f69a-8574-49e7-bc3a-6c030730e413",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import parfit.parfit as pf\n",
    "grid = {\n",
    "    'C' : np.logspace(-4, 4, 50),\n",
    "    'penalty': ['l2'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "paramGrid = ParameterGrid(grid)\n",
    "bestModel, bestScore, allModels, allScores = pf.bestFit(LogisticRegression, paramGrid,\n",
    "           X_train_new, y_train, X_val_new, y_val, \n",
    "           metric = accuracy_score,\n",
    "           scoreLabel = \"AUC\")\n",
    "print(bestModel, '\\n',bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "id": "5n6be4uQP4FG",
    "outputId": "485b24a2-d926-406e-9533-cbcad77501a3"
   },
   "outputs": [],
   "source": [
    "# Test SGD\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import parfit.parfit as pf\n",
    "\n",
    "grid = {\n",
    "    'alpha': [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0], # learning rate\n",
    "    'loss': ['log'], # logistic regression,\n",
    "    'penalty': ['l2'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "paramGrid = ParameterGrid(grid)\n",
    "\n",
    "bestModel, bestScore, allModels, allScores = pf.bestFit(SGDClassifier, paramGrid,\n",
    "           X_train_new, y_train, X_val_new, y_val, \n",
    "           metric = accuracy_score,\n",
    "           scoreLabel = \"AUC\")\n",
    "\n",
    "print(bestModel,'\\n\\n' ,bestScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4rk4oSAVxbs"
   },
   "source": [
    "<a id='references'></a>\n",
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lCoUJByVxbs"
   },
   "source": [
    "TF-IDF Explained And Python Sklearn Implementation :\n",
    "https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275\n",
    "\n",
    "Decision Trees Explained Easily :\n",
    "https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248\n",
    "\n",
    "Understanding Random Forests Classifiers in Python :\n",
    "https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "\n",
    "What is LightGBM, How to implement it? How to fine tune the parameters?\n",
    "https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n",
    "\n",
    "Using word2vec embeddings as featrues :\n",
    "https://www.kaggle.com/vladislavkisin/word2vec-in-supervised-nlp-tasks-shortcut\n",
    "\n",
    "A hands-on intuitive approach to Deep Learning Methods for Text Data â€” Word2Vec, GloVe and FastText\n",
    "https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\n",
    "\n",
    "How to make SGD Classifier perform as well as Logistic Regression\n",
    "https://towardsdatascience.com/how-to-make-sgd-classifier-perform-as-well-as-logistic-regression-using-parfit-cc10bca2d3c4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH7KfbWdVxbs"
   },
   "source": [
    "[Back to top â†‘](#Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dstzFfOrP4FL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-VqeCRDaVxXY",
    "x9HLGvDNVxYM",
    "3TPRVVKQVxYO",
    "7rdfD0TkVxYO",
    "qL8jpnPxVxYP",
    "UCplaYUjVxYQ",
    "5QJEmvWVVxYQ",
    "LvDcaHe-VxYU",
    "25NQkdQ6VxYX"
   ],
   "name": "Climate_change_updated_2_0_Copy1_TEST. version 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
